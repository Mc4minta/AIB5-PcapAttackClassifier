{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMdlVbS0I0TsOB4bCKyDXy7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mc4minta/AIB5-PcapAttackClassifier/blob/main/ProcessTestSetPCAP_FTPSSH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9BiThwkbr4R",
        "outputId": "2cb71a41-98f3-4a8e-dfdd-ccc4b4de7b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ftpbrute.zip, sshbrute.zip >> .csv"
      ],
      "metadata": {
        "id": "xS2K7o-O1c1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⏲ CICFLOWMETER v.3"
      ],
      "metadata": {
        "id": "nW0RhNABnolD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libpcap-dev # install libpcap-dev\n",
        "!wget https://codeberg.org/iortega/TCPDUMP_and_CICFlowMeter/archive/master:CICFlowMeters/CICFlowMeter-3.0.zip # download CICFlowMeter3.0.zip\n",
        "!unzip CICFlowMeter-3.0.zip -d CICFlowMeter-3.0 # Extract CICFlowMeter3.0.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yr_nV0XEnTDq",
        "outputId": "314e777c-eb95-4299-afe7-b2d9d1329acb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libdbus-1-dev libpcap0.8 libpcap0.8-dev\n",
            "The following NEW packages will be installed:\n",
            "  libdbus-1-dev libpcap-dev libpcap0.8 libpcap0.8-dev\n",
            "0 upgraded, 4 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 607 kB of archives.\n",
            "After this operation, 2,238 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcap0.8 amd64 1.10.1-4ubuntu1.22.04.1 [145 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-dev amd64 1.12.20-2ubuntu4.1 [188 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcap0.8-dev amd64 1.10.1-4ubuntu1.22.04.1 [270 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcap-dev amd64 1.10.1-4ubuntu1.22.04.1 [3,326 B]\n",
            "Fetched 607 kB in 0s (4,320 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpcap0.8:amd64.\n",
            "(Reading database ... 126109 files and directories currently installed.)\n",
            "Preparing to unpack .../libpcap0.8_1.10.1-4ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libpcap0.8:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Selecting previously unselected package libdbus-1-dev:amd64.\n",
            "Preparing to unpack .../libdbus-1-dev_1.12.20-2ubuntu4.1_amd64.deb ...\n",
            "Unpacking libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Selecting previously unselected package libpcap0.8-dev:amd64.\n",
            "Preparing to unpack .../libpcap0.8-dev_1.10.1-4ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libpcap0.8-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Selecting previously unselected package libpcap-dev:amd64.\n",
            "Preparing to unpack .../libpcap-dev_1.10.1-4ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libpcap-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Setting up libpcap0.8:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Setting up libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Setting up libpcap0.8-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Setting up libpcap-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "--2025-06-02 10:58:20--  https://codeberg.org/iortega/TCPDUMP_and_CICFlowMeter/archive/master:CICFlowMeters/CICFlowMeter-3.0.zip\n",
            "Resolving codeberg.org (codeberg.org)... 217.197.84.140, 2a0a:4580:103f:c0de::1\n",
            "Connecting to codeberg.org (codeberg.org)|217.197.84.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15039922 (14M) [application/octet-stream]\n",
            "Saving to: ‘CICFlowMeter-3.0.zip’\n",
            "\n",
            "CICFlowMeter-3.0.zi 100%[===================>]  14.34M  13.0MB/s    in 1.1s    \n",
            "\n",
            "2025-06-02 10:58:23 (13.0 MB/s) - ‘CICFlowMeter-3.0.zip’ saved [15039922/15039922]\n",
            "\n",
            "Archive:  CICFlowMeter-3.0.zip\n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/LICENSE.txt  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/README.md  \n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter.bat  \n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/CICFlowMeter-3.0.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/animal-sniffer-annotations-1.14.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/checker-compat-qual-2.0.0.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/commons-io-2.5.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/commons-lang3-3.6.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/commons-math3-3.5.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/error_prone_annotations-2.1.3.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/guava-23.6-jre.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/hamcrest-core-1.3.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/j2objc-annotations-1.1.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/java-cup-0.11a.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/jfreechart-1.5.0.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/jnetpcap-1.4.r1425-1g.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/jsr305-1.3.9.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/junit-4.12.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/log4j-1.2.17.jar  \n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/jnetpcap-pcap100.dll  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/jnetpcap.dll  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/libjnetpcap-pcap100.so  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/libjnetpcap.so  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/slf4j-api-1.7.25.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/slf4j-log4j12-1.7.25.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/tika-core-1.17.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/weka-stable-3.6.14.jar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af5a557d",
        "outputId": "52da7528-a430-4808-a4f3-defbeff95859"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the directory paths\n",
        "in_directory = 'data/in'\n",
        "out_directory = 'data/out'\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "os.makedirs(in_directory, exist_ok=True)\n",
        "os.makedirs(out_directory, exist_ok=True)\n",
        "\n",
        "print(f\"Directories '{in_directory}' and '{out_directory}' created (if they didn't exist).\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories 'data/in' and 'data/out' created (if they didn't exist).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ FTPBruteforce - GET PCAP FILES"
      ],
      "metadata": {
        "id": "CmV1c39QnUV4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96b5d445",
        "outputId": "4588d315-f4df-4d18-d1af-609a8fce4180"
      },
      "source": [
        "import os\n",
        "directory_path = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline'\n",
        "\n",
        "# Check if the directory exists before listing its contents\n",
        "if os.path.exists(directory_path):\n",
        "  # List the contents of the directory\n",
        "  contents = os.listdir(directory_path)\n",
        "\n",
        "  # Print the contents\n",
        "  for item in contents:\n",
        "    print(item)\n",
        "else:\n",
        "  print(f\"Directory not found: {directory_path}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS.zip\n",
            "DDoS.zip\n",
            "PortScan.zip\n",
            "Benign.zip\n",
            "FTPBruteforce.zip\n",
            "SSHBruteforce.zip\n",
            "DoS-HTTP-Flood.zip\n",
            "DoS-SlowRate.zip\n",
            "Benign2.zip\n",
            "DoS-overall.zip\n",
            "DoS-Layer3and4.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7b1dacb",
        "outputId": "f86f7ec0-adb8-4c71-9357-71dbb80f1b1e"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline/FTPBruteforce.zip'\n",
        "destination_directory = '/content/'\n",
        "\n",
        "# Unzip the file\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(destination_directory)\n",
        "    print(f\"'{zip_file_path}' unzipped to '{destination_directory}'.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Zip file not found at '{zip_file_path}'\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: '{zip_file_path}' is not a valid zip file.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline/FTPBruteforce.zip' unzipped to '/content/'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ FTPBruteforce - Convert to .csv"
      ],
      "metadata": {
        "id": "iHYMIgR8SaDp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f302c3a4-a7bb-40d5-8c9d-eb654ee5389c",
        "id": "FKZGSsKjSaDp"
      },
      "source": [
        "import os\n",
        "\n",
        "dos_directory = 'FTPBruteforce'\n",
        "pcap_files = [f for f in os.listdir(dos_directory) if f.endswith('.pcap')]\n",
        "\n",
        "if pcap_files:\n",
        "    print(f\"Found {len(pcap_files)} .pcap files in '{dos_directory}':\")\n",
        "    for pcap_file in pcap_files:\n",
        "        print(pcap_file)\n",
        "else:\n",
        "    print(f\"No .pcap files found in '{dos_directory}'.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 .pcap files in 'FTPBruteforce':\n",
            "ftpbrute-ubuntu.pcap\n",
            "ftpbrute-kali.pcap\n",
            "bruteforce_ftp.pcap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d95bafa-4288-47c9-9d4c-2f7bb6cd1fe8",
        "id": "nJOLXp-kSaDq"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "# Define the attack type directory (change this variable for different attack types)\n",
        "attack_type = 'FTPBruteforce' # You can change this to 'DDoS', 'PortScan', etc.\n",
        "\n",
        "attack_directory = attack_type\n",
        "data_in_directory = 'data/in'\n",
        "data_out_directory = 'data/out'\n",
        "csv_destination_directory = f'{attack_type}_csv'  # Directory for CSV files based on attack type\n",
        "cicflowmeter_command = './CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter'\n",
        "\n",
        "# Create the CSV destination directory if it doesn't exist\n",
        "os.makedirs(csv_destination_directory, exist_ok=True)\n",
        "print(f\"Directory '{csv_destination_directory}' created (if it didn't exist).\")\n",
        "\n",
        "# Ensure the attack directory exists\n",
        "if not os.path.exists(attack_directory):\n",
        "    print(f\"Error: Attack directory '{attack_directory}' not found.\")\n",
        "else:\n",
        "    # Get the list of pcap files in the attack directory\n",
        "    pcap_files = [f for f in os.listdir(attack_directory) if f.endswith('.pcap')]\n",
        "\n",
        "    if pcap_files:\n",
        "        print(f\"Processing {len(pcap_files)} .pcap files in '{attack_directory}'...\")\n",
        "        for pcap_file in pcap_files:\n",
        "            source_path = os.path.join(attack_directory, pcap_file)\n",
        "            dest_in_path = os.path.join(data_in_directory, pcap_file)\n",
        "\n",
        "            print(f\"\\nProcessing: {pcap_file}\")\n",
        "\n",
        "            # Step 2a: Move to data/in\n",
        "            print(f\"Moving '{pcap_file}' to '{data_in_directory}'...\")\n",
        "            shutil.move(source_path, data_in_directory)\n",
        "\n",
        "            # Step 2b: Run CICFlowMeter\n",
        "            print(\"Running CICFlowMeter...\")\n",
        "            try:\n",
        "                # The CICFlowMeter command expects the input directory to be 'data/in' and outputs to 'data/out'\n",
        "                subprocess.run([cicflowmeter_command], check=True, capture_output=True, text=True)\n",
        "                print(\"CICFlowMeter finished successfully.\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"Error running CICFlowMeter: {e}\")\n",
        "                print(f\"Stdout: {e.stdout}\")\n",
        "                print(f\"Stderr: {e.stderr}\")\n",
        "                # Move the file back even if there was an error\n",
        "                print(f\"Moving '{pcap_file}' back to '{attack_directory}' due to error.\")\n",
        "                shutil.move(dest_in_path, attack_directory)\n",
        "                continue # Move to the next file\n",
        "\n",
        "            # Step 2c: Move results - Move CSV to DoS_csv and original pcap back to DoS\n",
        "            print(f\"Moving results from '{data_out_directory}' to '{csv_destination_directory}' and original pcap back to '{attack_directory}'...\")\n",
        "            output_files = os.listdir(data_out_directory)\n",
        "            for output_file in output_files:\n",
        "                # Check if the file is a CSV file generated by CICFlowMeter\n",
        "                if output_file.endswith('_ISCX.csv'):\n",
        "                    source_out_path = os.path.join(data_out_directory, output_file)\n",
        "                    dest_csv_path = os.path.join(csv_destination_directory, output_file)\n",
        "                    shutil.move(source_out_path, dest_csv_path)\n",
        "                    print(f\"Moved '{output_file}' to '{csv_destination_directory}'.\")\n",
        "\n",
        "            # Move the original pcap file back to the attack directory\n",
        "            # We need to find the file in data/in after processing.\n",
        "            # Assuming only one pcap file is in data/in at a time during the loop.\n",
        "            processed_pcap_files_in_in = os.listdir(data_in_directory)\n",
        "            for processed_pcap_file in processed_pcap_files_in_in:\n",
        "                 if processed_pcap_file.endswith('.pcap'):\n",
        "                    processed_in_path = os.path.join(data_in_directory, processed_pcap_file)\n",
        "                    original_source_path = os.path.join(attack_directory, processed_pcap_file) # Construct original path\n",
        "                    shutil.move(processed_in_path, original_source_path) # Move from data/in back to original location\n",
        "                    print(f\"Moved '{processed_pcap_file}' back to '{attack_directory}'.\")\n",
        "\n",
        "\n",
        "            # Step 2d: Clean up data/in and data/out\n",
        "            print(\"Cleaning up temporary directories...\")\n",
        "            # Clean up any remaining files in data/out (should have been moved, but just in case)\n",
        "            remaining_out_files = os.listdir(data_out_directory)\n",
        "            for file in remaining_out_files:\n",
        "                 os.remove(os.path.join(data_out_directory, file))\n",
        "\n",
        "            print(\"Cleanup complete.\")\n",
        "\n",
        "\n",
        "        print(f\"\\nFinished processing all .pcap files in the '{attack_directory}' folder.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"No .pcap files found in '{attack_directory}' to process.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'FTPBruteforce_csv' created (if it didn't exist).\n",
            "Processing 3 .pcap files in 'FTPBruteforce'...\n",
            "\n",
            "Processing: ftpbrute-ubuntu.pcap\n",
            "Moving 'ftpbrute-ubuntu.pcap' to 'data/in'...\n",
            "Running CICFlowMeter...\n",
            "CICFlowMeter finished successfully.\n",
            "Moving results from 'data/out' to 'FTPBruteforce_csv' and original pcap back to 'FTPBruteforce'...\n",
            "Moved 'ftpbrute-ubuntu_ISCX.csv' to 'FTPBruteforce_csv'.\n",
            "Moved 'ftpbrute-ubuntu.pcap' back to 'FTPBruteforce'.\n",
            "Cleaning up temporary directories...\n",
            "Cleanup complete.\n",
            "\n",
            "Processing: ftpbrute-kali.pcap\n",
            "Moving 'ftpbrute-kali.pcap' to 'data/in'...\n",
            "Running CICFlowMeter...\n",
            "CICFlowMeter finished successfully.\n",
            "Moving results from 'data/out' to 'FTPBruteforce_csv' and original pcap back to 'FTPBruteforce'...\n",
            "Moved 'ftpbrute-kali_ISCX.csv' to 'FTPBruteforce_csv'.\n",
            "Moved 'ftpbrute-kali.pcap' back to 'FTPBruteforce'.\n",
            "Cleaning up temporary directories...\n",
            "Cleanup complete.\n",
            "\n",
            "Processing: bruteforce_ftp.pcap\n",
            "Moving 'bruteforce_ftp.pcap' to 'data/in'...\n",
            "Running CICFlowMeter...\n",
            "CICFlowMeter finished successfully.\n",
            "Moving results from 'data/out' to 'FTPBruteforce_csv' and original pcap back to 'FTPBruteforce'...\n",
            "Moved 'bruteforce_ftp_ISCX.csv' to 'FTPBruteforce_csv'.\n",
            "Moved 'bruteforce_ftp.pcap' back to 'FTPBruteforce'.\n",
            "Cleaning up temporary directories...\n",
            "Cleanup complete.\n",
            "\n",
            "Finished processing all .pcap files in the 'FTPBruteforce' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b50877f-5734-47a6-bed6-bf6dac635ee6",
        "id": "6VTPCIf1SaDs"
      },
      "source": [
        "! zip -r FTPBruteforce_csv.zip FTPBruteforce_csv"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: FTPBruteforce_csv/ (stored 0%)\n",
            "  adding: FTPBruteforce_csv/ftpbrute-ubuntu_ISCX.csv (deflated 82%)\n",
            "  adding: FTPBruteforce_csv/ftpbrute-kali_ISCX.csv (deflated 83%)\n",
            "  adding: FTPBruteforce_csv/bruteforce_ftp_ISCX.csv (deflated 82%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ SSHBruteforce - GET PCAP FILES"
      ],
      "metadata": {
        "id": "wUBRK26GSXtY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593c54af-2fae-4d01-9507-91f3618c4cea",
        "id": "Y0rW3W7nSXtZ"
      },
      "source": [
        "import os\n",
        "directory_path = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline'\n",
        "\n",
        "# Check if the directory exists before listing its contents\n",
        "if os.path.exists(directory_path):\n",
        "  # List the contents of the directory\n",
        "  contents = os.listdir(directory_path)\n",
        "\n",
        "  # Print the contents\n",
        "  for item in contents:\n",
        "    print(item)\n",
        "else:\n",
        "  print(f\"Directory not found: {directory_path}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS.zip\n",
            "DDoS.zip\n",
            "PortScan.zip\n",
            "Benign.zip\n",
            "FTPBruteforce.zip\n",
            "SSHBruteforce.zip\n",
            "DoS-HTTP-Flood.zip\n",
            "DoS-SlowRate.zip\n",
            "Benign2.zip\n",
            "DoS-overall.zip\n",
            "DoS-Layer3and4.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c25151-3b14-4eeb-9794-fed47e4295f8",
        "id": "RUprDxoYSXta"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline/SSHBruteforce.zip'\n",
        "destination_directory = '/content/'\n",
        "\n",
        "# Unzip the file\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(destination_directory)\n",
        "    print(f\"'{zip_file_path}' unzipped to '{destination_directory}'.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Zip file not found at '{zip_file_path}'\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: '{zip_file_path}' is not a valid zip file.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline/SSHBruteforce.zip' unzipped to '/content/'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ SSHBruteforce - Convert to .csv"
      ],
      "metadata": {
        "id": "0vJDU29IvE2y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a2e7d3b",
        "outputId": "696cfb5f-0b39-4279-b8d6-f616ff1142a1"
      },
      "source": [
        "import os\n",
        "\n",
        "dos_directory = 'SSHBruteforce'\n",
        "pcap_files = [f for f in os.listdir(dos_directory) if f.endswith('.pcap')]\n",
        "\n",
        "if pcap_files:\n",
        "    print(f\"Found {len(pcap_files)} .pcap files in '{dos_directory}':\")\n",
        "    for pcap_file in pcap_files:\n",
        "        print(pcap_file)\n",
        "else:\n",
        "    print(f\"No .pcap files found in '{dos_directory}'.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 .pcap files in 'SSHBruteforce':\n",
            "sshbrute-kali.pcap\n",
            "bruteforce_ssh.pcap\n",
            "sshbrute-ubuntu.pcap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2df2800f",
        "outputId": "0db819e8-a9f4-4c49-bf34-8acfb8d0d6fb"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "# Define the attack type directory (change this variable for different attack types)\n",
        "attack_type = 'SSHBruteforce' # You can change this to 'DDoS', 'PortScan', etc.\n",
        "\n",
        "attack_directory = attack_type\n",
        "data_in_directory = 'data/in'\n",
        "data_out_directory = 'data/out'\n",
        "csv_destination_directory = f'{attack_type}_csv'  # Directory for CSV files based on attack type\n",
        "cicflowmeter_command = './CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter'\n",
        "\n",
        "# Create the CSV destination directory if it doesn't exist\n",
        "os.makedirs(csv_destination_directory, exist_ok=True)\n",
        "print(f\"Directory '{csv_destination_directory}' created (if it didn't exist).\")\n",
        "\n",
        "# Ensure the attack directory exists\n",
        "if not os.path.exists(attack_directory):\n",
        "    print(f\"Error: Attack directory '{attack_directory}' not found.\")\n",
        "else:\n",
        "    # Get the list of pcap files in the attack directory\n",
        "    pcap_files = [f for f in os.listdir(attack_directory) if f.endswith('.pcap')]\n",
        "\n",
        "    if pcap_files:\n",
        "        print(f\"Processing {len(pcap_files)} .pcap files in '{attack_directory}'...\")\n",
        "        for pcap_file in pcap_files:\n",
        "            source_path = os.path.join(attack_directory, pcap_file)\n",
        "            dest_in_path = os.path.join(data_in_directory, pcap_file)\n",
        "\n",
        "            print(f\"\\nProcessing: {pcap_file}\")\n",
        "\n",
        "            # Step 2a: Move to data/in\n",
        "            print(f\"Moving '{pcap_file}' to '{data_in_directory}'...\")\n",
        "            shutil.move(source_path, data_in_directory)\n",
        "\n",
        "            # Step 2b: Run CICFlowMeter\n",
        "            print(\"Running CICFlowMeter...\")\n",
        "            try:\n",
        "                # The CICFlowMeter command expects the input directory to be 'data/in' and outputs to 'data/out'\n",
        "                subprocess.run([cicflowmeter_command], check=True, capture_output=True, text=True)\n",
        "                print(\"CICFlowMeter finished successfully.\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"Error running CICFlowMeter: {e}\")\n",
        "                print(f\"Stdout: {e.stdout}\")\n",
        "                print(f\"Stderr: {e.stderr}\")\n",
        "                # Move the file back even if there was an error\n",
        "                print(f\"Moving '{pcap_file}' back to '{attack_directory}' due to error.\")\n",
        "                shutil.move(dest_in_path, attack_directory)\n",
        "                continue # Move to the next file\n",
        "\n",
        "            # Step 2c: Move results - Move CSV to DoS_csv and original pcap back to DoS\n",
        "            print(f\"Moving results from '{data_out_directory}' to '{csv_destination_directory}' and original pcap back to '{attack_directory}'...\")\n",
        "            output_files = os.listdir(data_out_directory)\n",
        "            for output_file in output_files:\n",
        "                # Check if the file is a CSV file generated by CICFlowMeter\n",
        "                if output_file.endswith('_ISCX.csv'):\n",
        "                    source_out_path = os.path.join(data_out_directory, output_file)\n",
        "                    dest_csv_path = os.path.join(csv_destination_directory, output_file)\n",
        "                    shutil.move(source_out_path, dest_csv_path)\n",
        "                    print(f\"Moved '{output_file}' to '{csv_destination_directory}'.\")\n",
        "\n",
        "            # Move the original pcap file back to the attack directory\n",
        "            # We need to find the file in data/in after processing.\n",
        "            # Assuming only one pcap file is in data/in at a time during the loop.\n",
        "            processed_pcap_files_in_in = os.listdir(data_in_directory)\n",
        "            for processed_pcap_file in processed_pcap_files_in_in:\n",
        "                 if processed_pcap_file.endswith('.pcap'):\n",
        "                    processed_in_path = os.path.join(data_in_directory, processed_pcap_file)\n",
        "                    original_source_path = os.path.join(attack_directory, processed_pcap_file) # Construct original path\n",
        "                    shutil.move(processed_in_path, original_source_path) # Move from data/in back to original location\n",
        "                    print(f\"Moved '{processed_pcap_file}' back to '{attack_directory}'.\")\n",
        "\n",
        "\n",
        "            # Step 2d: Clean up data/in and data/out\n",
        "            print(\"Cleaning up temporary directories...\")\n",
        "            # Clean up any remaining files in data/out (should have been moved, but just in case)\n",
        "            remaining_out_files = os.listdir(data_out_directory)\n",
        "            for file in remaining_out_files:\n",
        "                 os.remove(os.path.join(data_out_directory, file))\n",
        "\n",
        "            print(\"Cleanup complete.\")\n",
        "\n",
        "\n",
        "        print(f\"\\nFinished processing all .pcap files in the '{attack_directory}' folder.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"No .pcap files found in '{attack_directory}' to process.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'SSHBruteforce_csv' created (if it didn't exist).\n",
            "Processing 3 .pcap files in 'SSHBruteforce'...\n",
            "\n",
            "Processing: sshbrute-kali.pcap\n",
            "Moving 'sshbrute-kali.pcap' to 'data/in'...\n",
            "Running CICFlowMeter...\n",
            "CICFlowMeter finished successfully.\n",
            "Moving results from 'data/out' to 'SSHBruteforce_csv' and original pcap back to 'SSHBruteforce'...\n",
            "Moved 'sshbrute-kali_ISCX.csv' to 'SSHBruteforce_csv'.\n",
            "Moved 'sshbrute-kali.pcap' back to 'SSHBruteforce'.\n",
            "Cleaning up temporary directories...\n",
            "Cleanup complete.\n",
            "\n",
            "Processing: bruteforce_ssh.pcap\n",
            "Moving 'bruteforce_ssh.pcap' to 'data/in'...\n",
            "Running CICFlowMeter...\n",
            "CICFlowMeter finished successfully.\n",
            "Moving results from 'data/out' to 'SSHBruteforce_csv' and original pcap back to 'SSHBruteforce'...\n",
            "Moved 'bruteforce_ssh_ISCX.csv' to 'SSHBruteforce_csv'.\n",
            "Moved 'bruteforce_ssh.pcap' back to 'SSHBruteforce'.\n",
            "Cleaning up temporary directories...\n",
            "Cleanup complete.\n",
            "\n",
            "Processing: sshbrute-ubuntu.pcap\n",
            "Moving 'sshbrute-ubuntu.pcap' to 'data/in'...\n",
            "Running CICFlowMeter...\n",
            "CICFlowMeter finished successfully.\n",
            "Moving results from 'data/out' to 'SSHBruteforce_csv' and original pcap back to 'SSHBruteforce'...\n",
            "Moved 'sshbrute-ubuntu_ISCX.csv' to 'SSHBruteforce_csv'.\n",
            "Moved 'sshbrute-ubuntu.pcap' back to 'SSHBruteforce'.\n",
            "Cleaning up temporary directories...\n",
            "Cleanup complete.\n",
            "\n",
            "Finished processing all .pcap files in the 'SSHBruteforce' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ac1a5b0",
        "outputId": "acfe2659-4cee-4fcc-8f28-3c4257a3d5bd"
      },
      "source": [
        "! zip -r SSHBruteforce_csv.zip SSHBruteforce_csv"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: SSHBruteforce_csv/ (stored 0%)\n",
            "  adding: SSHBruteforce_csv/sshbrute-kali_ISCX.csv (deflated 82%)\n",
            "  adding: SSHBruteforce_csv/sshbrute-ubuntu_ISCX.csv (deflated 81%)\n",
            "  adding: SSHBruteforce_csv/bruteforce_ssh_ISCX.csv (deflated 80%)\n"
          ]
        }
      ]
    }
  ]
}