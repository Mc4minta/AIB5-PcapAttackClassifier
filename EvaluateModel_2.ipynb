{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TLm6-7pXFFmy",
        "srI7OsUjFAoz",
        "fL2Jdmy58F7C",
        "fFyVqFnOkshn",
        "iyfKM07nOPDu",
        "EZ_mNHJ7mHrt",
        "ZE5Hn1tQntgb",
        "aKPqgcBYThy9",
        "18RZ1HMbugQi",
        "VisBSN1_TlPz"
      ],
      "authorship_tag": "ABX9TyN3zoETAFm+HoBasQUrhoaV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mc4minta/AIB5-PcapAttackClassifier/blob/main/EvaluateModel_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Step for evaluation (my model)\n",
        "- list pcap zip\n",
        "  - in `/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline`\n",
        "- unzip each zip\n",
        "- iterate through each attack\n",
        "- iterate to each attack pcap files\n",
        "- convert to FlowCSV\n",
        "- process packet map\n",
        "- preprocess_df\n",
        "- load model\n",
        "- predict\n",
        "- combined label with packet_index\n",
        "- convert flow-label-index to packetindex-label\n",
        "- list of predicted label from high to low (final_df)\n",
        "\n",
        "## final_df format:\n",
        "\n",
        "| pcap label     | packet label   | ranked_label                    |\n",
        "| -------------- | -------------- | ------------------------------- |\n",
        "| FTP-Bruteforce | FTP-Bruteforce | [FTP-Bruteforce,SSH-Bruteforce] |\n",
        "| Benign         | Benign         | [Benign]                        |\n",
        "\n",
        "## Evaluate by comparing:\n",
        "- pcap label and label\n",
        "- y_test = pcap label\n",
        "- y_pred = label\n",
        "\n",
        "## label_rank\n",
        "- is for tie breaker with baseline just in case"
      ],
      "metadata": {
        "id": "dWsPbK9AGFIL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c967fa09",
        "outputId": "4d964b50-f01b-4642-e4f0-b8e8af5188a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list pcap zip\n",
        "import os\n",
        "pcap_zip_dir = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline/'\n",
        "files = os.listdir(pcap_zip_dir)\n",
        "for file in files:\n",
        "  print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMMIz8EPIRK9",
        "outputId": "14a60759-2f97-4c98-ffe5-5f5300dbf078"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS.zip\n",
            "DDoS.zip\n",
            "PortScan.zip\n",
            "Benign.zip\n",
            "DoS-HTTP-Flood.zip\n",
            "DoS-SlowRate.zip\n",
            "Benign2.zip\n",
            "DoS-overall.zip\n",
            "DoS-Layer3and4.zip\n",
            "FTP-Bruteforce.zip\n",
            "SSH-Bruteforce.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list flow zip\n",
        "import os\n",
        "pcap_zip_dir = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv/'\n",
        "files = os.listdir(pcap_zip_dir)\n",
        "for file in files:\n",
        "  print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnsGRCFPEK8m",
        "outputId": "6118aa53-7c09-49d5-a3c0-897bafae5db4"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS_csv.zip\n",
            "DDoS_csv.zip\n",
            "PortScan_csv.zip\n",
            "Benign_csv.zip\n",
            "Benign2_csv.zip\n",
            "DoS-HTTP-Flood_csv.zip\n",
            "DoS-Layer3and4_csv.zip\n",
            "DoS-overall_csv.zip\n",
            "FTP-Bruteforce_csv.zip\n",
            "SSH-Bruteforce_csv.zip\n",
            "DoS-SlowRate_csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list each attack folder without '.zip' and append to attacks[]\n",
        "pcap_zip_dir = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline/'\n",
        "files = os.listdir(pcap_zip_dir)\n",
        "attacks = []\n",
        "for file in files:\n",
        "  attacks.append(file[:-4])\n",
        "for attack in attacks:\n",
        "  print(attack)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNcbNRbgLhfh",
        "outputId": "f7c99914-eea5-43fc-eb78-02159646153d"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS\n",
            "DDoS\n",
            "PortScan\n",
            "Benign\n",
            "DoS-HTTP-Flood\n",
            "DoS-SlowRate\n",
            "Benign2\n",
            "DoS-overall\n",
            "DoS-Layer3and4\n",
            "FTP-Bruteforce\n",
            "SSH-Bruteforce\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attacks = ['FTP-Bruteforce'] # ,'SSH-Bruteforce']"
      ],
      "metadata": {
        "id": "zs24NqQWRCt9"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to unzip(attack.zip)\n",
        "import zipfile\n",
        "\n",
        "def unzip_attack_zip(attack):\n",
        "  pcap_zip_dir = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForBaseline/'\n",
        "  if(attack[-4:]=='.zip'):\n",
        "    zip_file_name = attack\n",
        "  else:\n",
        "    zip_file_name = attack + '.zip'\n",
        "  zip_file_path = os.path.join(pcap_zip_dir, zip_file_name)\n",
        "  destination_directory = '/content/'\n",
        "  try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(destination_directory)\n",
        "    print(f\"'{zip_file_name}' unzipped to '{destination_directory}'.\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error : {e}\")\n",
        "\n",
        "# unzip_attack_zip('DDoS')"
      ],
      "metadata": {
        "id": "COBbu0u9JJe3"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to unzip(attack_csv.zip)\n",
        "import zipfile\n",
        "\n",
        "def unzip_attack_flow(attack):\n",
        "  pcap_zip_dir = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv/'\n",
        "  zip_file_name = attack + '_csv.zip'\n",
        "  zip_file_path = os.path.join(pcap_zip_dir, zip_file_name)\n",
        "  destination_directory = '/content/'\n",
        "  try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(destination_directory)\n",
        "    print(f\"'{zip_file_name}' unzipped to '{destination_directory}'.\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error : {e}\")\n",
        "\n",
        "# unzip_attack_flow('DDoS')"
      ],
      "metadata": {
        "id": "VqQjqkKbEXPc"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through each attack_csv .zip and unzip it\n",
        "for attack in attacks:\n",
        "  print(f\"Processing {attack}_csv...\")\n",
        "  if(f'{attack}_csv' not in os.listdir('/content/')):\n",
        "    unzip_attack_flow(attack)\n",
        "  else:\n",
        "    print(f\"{attack}_csv already unzipped\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCPKIXyUEj69",
        "outputId": "509567d9-b6af-4dd7-e08e-03c4febf8f33"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing FTP-Bruteforce_csv...\n",
            "FTP-Bruteforce_csv already unzipped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through each attack .zip and unzip it\n",
        "for attack in attacks:\n",
        "  print(f\"Processing {attack}...\")\n",
        "  if(attack not in os.listdir('/content/')):\n",
        "    unzip_attack_zip(attack)\n",
        "  else:\n",
        "    print(f\"{attack} already unzipped\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKHO1ouhJmt9",
        "outputId": "0477738c-9a93-4458-ca6d-1ada775d918e"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing FTP-Bruteforce...\n",
            "FTP-Bruteforce already unzipped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attack in attacks:\n",
        "  print('--------------------------------')\n",
        "  print(f\"PCAP for {attack}\")\n",
        "  print('--------------------------------')\n",
        "  attack_pcaps = os.listdir(f'/content/{attack}')\n",
        "  for attack_pcap in attack_pcaps:\n",
        "    print(attack_pcap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTosyZGCOQjb",
        "outputId": "8aedea0a-28c4-479e-9411-487b770cecea"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "PCAP for FTP-Bruteforce\n",
            "--------------------------------\n",
            "bruteforce_ftp.pcap\n",
            "ftpbrute-ubuntu.pcap\n",
            "ftpbrute-kali.pcap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attack in attacks:\n",
        "  print('--------------------------------')\n",
        "  print(f\"CSV for {attack}\")\n",
        "  print('--------------------------------')\n",
        "  attack_flows = os.listdir(f'/content/{attack}_csv')\n",
        "  for attack_flow in attack_flows:\n",
        "    print(attack_flow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4313y7t4Gua6",
        "outputId": "414d6d2e-e61d-4276-9ab6-68d9b35adc26"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "CSV for FTP-Bruteforce\n",
            "--------------------------------\n",
            "ftpbrute-ubuntu_ISCX.csv\n",
            "ftpbrute-kali_ISCX.csv\n",
            "bruteforce_ftp_ISCX.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Map"
      ],
      "metadata": {
        "id": "d3lxmyW1G2xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create attack_index folder\n",
        "import os\n",
        "for attack in attacks:\n",
        "  os.makedirs(f'/content/{attack}_index', exist_ok=True)\n",
        "  print(f\"Created {attack}_index folder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzjTd5l_O1-t",
        "outputId": "0a97ced6-5077-4404-f943-b45180d266c6"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created DoS_index folder\n",
            "Created DDoS_index folder\n",
            "Created PortScan_index folder\n",
            "Created Benign_index folder\n",
            "Created DoS-HTTP-Flood_index folder\n",
            "Created DoS-SlowRate_index folder\n",
            "Created Benign2_index folder\n",
            "Created DoS-overall_index folder\n",
            "Created DoS-Layer3and4_index folder\n",
            "Created FTP-Bruteforce_index folder\n",
            "Created SSH-Bruteforce_index folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scapy > /content/log.txt"
      ],
      "metadata": {
        "id": "987RkmArRbp1"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import csv\n",
        "import sys\n",
        "from collections import namedtuple\n",
        "import ipaddress # For robust IP address comparison\n",
        "import pandas as pd # Import pandas\n",
        "\n",
        "# Import Scapy for PCAP reading and parsing\n",
        "# You might need to install it: pip install scapy\n",
        "try:\n",
        "    from scapy.all import rdpcap, IP, TCP, UDP\n",
        "except ImportError:\n",
        "    print(\"Scapy not found. Please install it using: pip install scapy\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Define a Packet structure to standardize data from Scapy packets\n",
        "# 'index' corresponds to the sequential position in the PCAP file,\n",
        "# which is similar to the 'id' in CICFlowMeter's BasicPacketInfo.java\n",
        "Packet = namedtuple('Packet', ['index', 'timestamp', 'src_ip', 'dst_ip', 'src_port', 'dst_port', 'protocol', 'length', 'has_fin_flag'])\n",
        "\n",
        "class Flow:\n",
        "    \"\"\"\n",
        "    Simulates a network flow, similar to BasicFlow.java.\n",
        "    A flow is identified by its 5-tuple and stores a list of packet indices\n",
        "    that belong to this flow. It also tracks basic flow statistics and timestamps.\n",
        "    \"\"\"\n",
        "    def __init__(self, flow_key, first_packet):\n",
        "        self.flow_key = flow_key\n",
        "        # This list directly maps the flow to its packet indices (IDs)\n",
        "        self.packet_indices = [first_packet.index]\n",
        "        # Store packet timestamps as well for export\n",
        "        self.packet_timestamps = [int(first_packet.timestamp * 1_000_000)] # Convert to microseconds\n",
        "\n",
        "        self.start_time = int(first_packet.timestamp * 1_000_000) # Microseconds\n",
        "        self.last_packet_time = int(first_packet.timestamp * 1_000_000) # Microseconds\n",
        "        self.packet_count = 1\n",
        "        self.byte_count = first_packet.length\n",
        "        self.fwd_packets = [] # Simulating BasicFlow's 'forward' list\n",
        "        self.bwd_packets = [] # Simulating BasicFlow's 'backward' list\n",
        "\n",
        "        # Determine the initial direction based on the first packet's original IPs\n",
        "        # This is used for 'forward' and 'backward' packet grouping within the flow,\n",
        "        # distinct from the canonical direction used for the flow_key.\n",
        "        self.initial_src_ip = first_packet.src_ip\n",
        "\n",
        "        # Add first packet to appropriate directional list\n",
        "        if self._is_forward_packet(first_packet):\n",
        "            self.fwd_packets.append(first_packet)\n",
        "        else:\n",
        "            self.bwd_packets.append(first_packet)\n",
        "\n",
        "    def add_packet(self, packet):\n",
        "        \"\"\"Adds a packet to the flow and updates flow statistics.\"\"\"\n",
        "        self.packet_indices.append(packet.index)\n",
        "        self.packet_timestamps.append(int(packet.timestamp * 1_000_000)) # Store timestamp in microseconds\n",
        "\n",
        "        self.packet_count += 1\n",
        "        self.byte_count += packet.length\n",
        "\n",
        "        # Update directional packet lists and IATs (simplified for simulation)\n",
        "        if self._is_forward_packet(packet):\n",
        "            self.fwd_packets.append(packet)\n",
        "            # In real CICFlowMeter, IATs and other stats would be updated here, e.g.:\n",
        "            # if len(self.fwd_packets) > 1:\n",
        "            #     self.fwd_iat.add_value(packet.timestamp - self.fwd_packets[-2].timestamp)\n",
        "        else:\n",
        "            self.bwd_packets.append(packet)\n",
        "            # if len(self.bwd_packets) > 1:\n",
        "            #     self.bwd_iat.add_value(packet.timestamp - self.bwd_packets[-2].timestamp)\n",
        "\n",
        "        # Update last packet time for overall flow duration/IAT calculation\n",
        "        self.last_packet_time = int(packet.timestamp * 1_000_000) # Microseconds\n",
        "\n",
        "    def get_flow_duration(self):\n",
        "        \"\"\"Calculates the duration of the flow in microseconds.\"\"\"\n",
        "        return self.last_packet_time - self.start_time\n",
        "\n",
        "    def _is_forward_packet(self, packet):\n",
        "        \"\"\"\n",
        "        Determines if a packet is in the forward direction relative to the flow's initial direction.\n",
        "        This uses the original src_ip of the *first* packet to define \"forward\" for feature accumulation,\n",
        "        which is consistent with CICFlowMeter's internal `BasicFlow` logic.\n",
        "        \"\"\"\n",
        "        return packet.src_ip == self.initial_src_ip\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Flow(key={self.flow_key}, total_packets={self.packet_count}, \"\n",
        "                f\"duration={self.get_flow_duration():.4f}us, \"\n",
        "                f\"total_bytes={self.byte_count}B, \"\n",
        "                f\"fwd_pkts={len(self.fwd_packets)}, bwd_pkts={len(self.bwd_packets)}, \"\n",
        "                f\"packet_indices={self.packet_indices})\")\n",
        "\n",
        "    def to_csv_row(self):\n",
        "        \"\"\"\n",
        "        Converts the flow data into a dictionary suitable for CSV writing.\n",
        "        This provides a simplified representation of the features CICFlowMeter extracts,\n",
        "        but crucially includes the 'Packet Indices' and 'Packet Timestamps' columns.\n",
        "        The 'Flow ID', 'Src IP', 'Dst IP', 'Src Port', 'Dst Port' are taken from the\n",
        "        canonical flow_key for consistency with CICFlowMeter's output format.\n",
        "        \"\"\"\n",
        "        # The flow_key tuple already holds the normalized 5-tuple as generated by generate_flow_key\n",
        "        canonical_src_ip, canonical_dst_ip, canonical_src_port, canonical_dst_port, proto = self.flow_key\n",
        "\n",
        "        return {\n",
        "            'Flow ID': f\"{canonical_src_ip}-{canonical_dst_ip}-{canonical_src_port}-{canonical_dst_port}-{proto}\",\n",
        "            'Src IP': canonical_src_ip,\n",
        "            'Src Port': canonical_src_port,\n",
        "            'Dst IP': canonical_dst_ip,\n",
        "            'Dst Port': canonical_dst_port,\n",
        "            'Protocol': proto,\n",
        "            'Flow Duration (us)': self.get_flow_duration(),\n",
        "            'Total Packets': self.packet_count,\n",
        "            'Total Bytes': self.byte_count,\n",
        "            'Fwd Packets': len(self.fwd_packets), # These counts are based on internal 'initial_src_ip'\n",
        "            'Bwd Packets': len(self.bwd_packets), # These counts are based on internal 'initial_src_ip'\n",
        "            'Packet Indices': str(self.packet_indices), # Convert list to string for CSV column\n",
        "            'Packet Timestamps': str(self.packet_timestamps) # Convert list to string for CSV column\n",
        "            # Add more CICFlowMeter-like features here if needed\n",
        "            # 'Flow Pkts/s': self.packet_count / (self.get_flow_duration() / 1_000_000.0) if self.get_flow_duration() > 0 else 0,\n",
        "            # 'Avg Fwd Pkt Len': sum(p.length for p in self.fwd_packets) / len(self.fwd_packets) if self.fwd_packets else 0,\n",
        "        }\n",
        "\n",
        "\n",
        "def generate_flow_key(packet):\n",
        "    \"\"\"\n",
        "    Generates a unique key for a flow based on the 5-tuple,\n",
        "    mimicking CICFlowMeter's Java BasicPacketInfo.generateFlowId() logic\n",
        "    for canonicalizing IP addresses and ports.\n",
        "\n",
        "    IMPORTANT: This function uses the raw protocol number, matching BasicPacketInfo.java.\n",
        "    Any mapping of non-TCP/UDP/ICMP protocols to '0' happens *after* Flow ID generation\n",
        "    in CICFlowMeter's pipeline (e.g., for display in FlowFeature.featureValue2String),\n",
        "    and is NOT part of the Flow ID itself.\n",
        "    \"\"\"\n",
        "    # Access attributes by name from the Packet namedtuple\n",
        "    src_ip_str = packet.src_ip\n",
        "    dst_ip_str = packet.dst_ip\n",
        "    src_port = packet.src_port\n",
        "    dst_port = packet.dst_port\n",
        "    protocol_int = packet.protocol # Use the raw protocol number here\n",
        "\n",
        "    # Use ipaddress for robust IP comparison, mirroring Java's byte-by-byte comparison\n",
        "    try:\n",
        "        src_ip_obj = ipaddress.ip_address(src_ip_str)\n",
        "        dst_ip_obj = ipaddress.ip_address(dst_ip_str)\n",
        "    except ValueError:\n",
        "        # Fallback for invalid IPs if any, should not happen with valid PCAP data\n",
        "        return (src_ip_str, dst_ip_str, src_port, dst_port, protocol_int)\n",
        "\n",
        "\n",
        "    # Determine 'forward' based on IP comparison: canonical_src_ip will be the \"smaller\" IP\n",
        "    if src_ip_obj < dst_ip_obj:\n",
        "        normalized_src_ip = src_ip_str\n",
        "        normalized_dst_ip = dst_ip_str\n",
        "        normalized_src_port = src_port\n",
        "        normalized_dst_port = dst_port\n",
        "    elif dst_ip_obj < src_ip_obj:\n",
        "        # Swap IPs and their corresponding ports for normalization\n",
        "        normalized_src_ip = dst_ip_str\n",
        "        normalized_dst_ip = src_ip_str\n",
        "        normalized_src_port = dst_port\n",
        "        normalized_dst_port = src_port\n",
        "    else: # IPs are equal (e.g., multicast or broadcast)\n",
        "        # If IPs are the same, Java's logic does NOT swap ports based on IP.\n",
        "        # It keeps original src/dst IPs and ports as they are.\n",
        "        normalized_src_ip = src_ip_str\n",
        "        normalized_dst_ip = dst_ip_str\n",
        "        normalized_src_port = src_port\n",
        "        normalized_dst_port = dst_port\n",
        "\n",
        "    # The canonical 5-tuple key for the hash map\n",
        "    return (normalized_src_ip, normalized_dst_ip, normalized_src_port, normalized_dst_port, protocol_int)\n",
        "\n",
        "def process_packets_into_flows(packets, flow_timeout_us=120000000, idle_timeout_us=5000000):\n",
        "    \"\"\"\n",
        "    Processes a list of packets and groups them into flows, simulating FlowGenerator.java.\n",
        "    Args:\n",
        "        packets (list): A list of Packet namedtuples, derived from PCAP.\n",
        "        flow_timeout_us (int): Max flow duration in microseconds (120 seconds).\n",
        "        idle_timeout_us (int): Max idle time within a flow in microseconds (5 seconds).\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are unique flow identifiers (combining 5-tuple and a counter)\n",
        "              and values are Flow objects.\n",
        "    \"\"\"\n",
        "    active_flows = {} # {flow_key_5_tuple: Flow_object}\n",
        "    completed_flows = {} # {unique_completed_flow_id: Flow_object}\n",
        "\n",
        "    # Packets are assumed to be already sorted by timestamp when passed from PCAP reader\n",
        "\n",
        "    completed_flow_counter = 0\n",
        "\n",
        "    for packet in packets:\n",
        "        flow_key = generate_flow_key(packet)\n",
        "        current_timestamp_us = int(packet.timestamp * 1_000_000) # Convert seconds to microseconds\n",
        "\n",
        "        # Check if this packet belongs to an existing active flow\n",
        "        if flow_key in active_flows:\n",
        "            flow = active_flows[flow_key]\n",
        "\n",
        "            # Check for IDLE timeout first (packet arrival AFTER idle period)\n",
        "            if (current_timestamp_us - flow.last_packet_time) > idle_timeout_us:\n",
        "                # Flow idle timed out, finish current flow and start new one\n",
        "                completed_flows[f\"{flow_key}_{completed_flow_counter}\"] = flow\n",
        "                completed_flow_counter += 1\n",
        "                active_flows.pop(flow_key) # Remove old flow from active\n",
        "\n",
        "                new_flow = Flow(flow_key, packet)\n",
        "                active_flows[flow_key] = new_flow\n",
        "\n",
        "            # Check for TOTAL flow timeout (flow duration)\n",
        "            elif (current_timestamp_us - flow.start_time) > flow_timeout_us:\n",
        "                # Flow timed out based on total duration, finish current flow and start new one\n",
        "                completed_flows[f\"{flow_key}_{completed_flow_counter}\"] = flow\n",
        "                completed_flow_counter += 1\n",
        "                active_flows.pop(flow_key) # Remove old flow from active\n",
        "\n",
        "                new_flow = Flow(flow_key, packet)\n",
        "                active_flows[flow_key] = new_flow\n",
        "\n",
        "            # Simulate TCP FIN flag termination\n",
        "            # Only apply if the protocol is TCP (6) and FIN flag is set.\n",
        "            # Add the FIN packet to the flow before deciding if it's finished.\n",
        "            elif packet.protocol == 6 and packet.has_fin_flag:\n",
        "                flow.add_packet(packet) # Add the FIN packet\n",
        "                completed_flows[f\"{flow_key}_{completed_flow_counter}\"] = flow\n",
        "                completed_flow_counter += 1\n",
        "                active_flows.pop(flow_key) # Remove from active flows as it's finished\n",
        "\n",
        "            # Otherwise, add packet to existing active flow\n",
        "            else:\n",
        "                flow.add_packet(packet)\n",
        "                # No explicit idle time update needed in Flow object here,\n",
        "                # as it's checked upon next packet arrival.\n",
        "\n",
        "        else:\n",
        "            # New flow, or a flow that previously completed and was removed from active_flows\n",
        "            new_flow = Flow(flow_key, packet)\n",
        "            active_flows[flow_key] = new_flow\n",
        "\n",
        "    # After processing all packets, move any remaining active flows to completed flows\n",
        "    for flow_key, flow in list(active_flows.items()): # Iterate over a copy to allow modification\n",
        "        completed_flows[f\"{flow_key}_{completed_flow_counter}\"] = flow\n",
        "        completed_flow_counter += 1\n",
        "        # No need to pop from active_flows here, as loop is over.\n",
        "\n",
        "    return completed_flows\n",
        "\n",
        "def extract_packet_info_from_pcap(pcap_file_path):\n",
        "    \"\"\"\n",
        "    Reads a PCAP file using Scapy and extracts relevant information into Packet namedtuples.\n",
        "    Assigns a sequential index to each packet as it's read.\n",
        "    Broadened to include all IP packets, not just TCP/UDP.\n",
        "    \"\"\"\n",
        "    print(f\"Reading packets from {pcap_file_path}...\")\n",
        "    extracted_packets = []\n",
        "\n",
        "    try:\n",
        "        packets_scapy = rdpcap(pcap_file_path)\n",
        "        total_packets = len(packets_scapy)\n",
        "        print(f\"Successfully read {total_packets} packets from {pcap_file_path}.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: PCAP file not found at {pcap_file_path}.\")\n",
        "        return [] # Return empty list if file not found\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading PCAP file {pcap_file_path}: {e}\")\n",
        "        return [] # Return empty list on other errors\n",
        "\n",
        "\n",
        "    for i, pkt in enumerate(packets_scapy):\n",
        "        src_ip = None\n",
        "        dst_ip = None\n",
        "        src_port = 0 # Default to 0 for non-TCP/UDP protocols or if ports are missing\n",
        "        dst_port = 0 # Default to 0 for non-TCP/UDP protocols or if ports are missing\n",
        "        protocol = None\n",
        "        has_fin = False\n",
        "\n",
        "        # Ensure IP layer exists\n",
        "        if IP in pkt:\n",
        "            src_ip = pkt[IP].src\n",
        "            dst_ip = pkt[IP].dst\n",
        "            protocol = pkt[IP].proto # e.g., 6 for TCP, 17 for UDP, 1 for ICMP, 2 for IGMP, etc.\n",
        "\n",
        "            # Check for transport layer (TCP or UDP) to get ports and flags\n",
        "            if TCP in pkt:\n",
        "                src_port = pkt[TCP].sport\n",
        "                dst_port = pkt[TCP].dport\n",
        "                has_fin = bool(pkt[TCP].flags & 0x01) # FIN is bit 0 in TCP flags\n",
        "            elif UDP in pkt:\n",
        "                src_port = pkt[UDP].sport\n",
        "                dst_port = pkt[UDP].dport\n",
        "            # For other IP protocols (like ICMP, IGMP, etc.), src_port and dst_port remain 0.\n",
        "\n",
        "            # Only process packets with valid IP information\n",
        "            # This condition is now implicitly true for any packet with an IP layer,\n",
        "            # as src_ip, dst_ip, and protocol will be extracted.\n",
        "            extracted_packets.append(Packet(\n",
        "                index=i,\n",
        "                timestamp=pkt.time, # Scapy's pkt.time is already in seconds (float)\n",
        "                src_ip=src_ip,\n",
        "                dst_ip=dst_ip,\n",
        "                src_port=src_port,\n",
        "                dst_port=dst_port,\n",
        "                protocol=protocol,\n",
        "                length=len(pkt), # Total packet length\n",
        "                has_fin_flag=has_fin\n",
        "            ))\n",
        "\n",
        "    # Scapy's rdpcap usually returns packets in capture order (by timestamp),\n",
        "    # but explicit sorting ensures strict chronological processing as in CICFlowMeter.\n",
        "    extracted_packets.sort(key=lambda p: p.timestamp)\n",
        "    print(f\"Extracted {len(extracted_packets)} valid packets from PCAP.\")\n",
        "    return extracted_packets,total_packets\n",
        "\n",
        "def extract_flows_from_pcap(pcap_file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Orchestrates the entire process of extracting network flows from a PCAP file,\n",
        "    mimicking CICFlowMeter's logic, and returns the flows as a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        pcap_file_path (str): The path to the input PCAP file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame where each row represents a discovered flow,\n",
        "                      including 'Packet Indices' and 'Packet Timestamps'.\n",
        "                      Returns an empty DataFrame if no valid packets are found or\n",
        "                      if PCAP file cannot be read.\n",
        "    \"\"\"\n",
        "    # Step 1: Extract packet information from the PCAP file\n",
        "    packets_from_pcap,total_packets = extract_packet_info_from_pcap(pcap_file_path)\n",
        "\n",
        "    if not packets_from_pcap:\n",
        "        print(\"No valid packets found or PCAP file could not be read. Returning empty DataFrame.\")\n",
        "        return pd.DataFrame() # Return empty DataFrame\n",
        "\n",
        "    print(\"\\nProcessing packets into flows (simulating CICFlowMeter logic)...\")\n",
        "    # Step 2: Process the extracted packets into flows\n",
        "    # Default timeouts are 120 seconds (flow) and 5 seconds (idle) for CICFlowMeter\n",
        "    flows_data = process_packets_into_flows(packets_from_pcap,\n",
        "                                            flow_timeout_us=120_000_000,\n",
        "                                            idle_timeout_us=5_000_000)\n",
        "\n",
        "    print(f\"\\nDiscovered {len(flows_data)} flows.\")\n",
        "\n",
        "    # Step 3: Convert discovered flows to a list of dictionaries for DataFrame creation\n",
        "    flows_list_of_dicts = []\n",
        "    for flow_unique_id, flow_obj in flows_data.items():\n",
        "        flows_list_of_dicts.append(flow_obj.to_csv_row())\n",
        "\n",
        "    # Create DataFrame from the list of flow dictionaries\n",
        "    flows_df = pd.DataFrame(flows_list_of_dicts)\n",
        "\n",
        "    # Step 4: Display a summary of generated flows (for console output)\n",
        "    if not flows_df.empty:\n",
        "        print(\"\\nHead of the generated Flows DataFrame:\")\n",
        "        print(flows_df.head())\n",
        "        print(\"\\nColumns in the generated Flows DataFrame:\")\n",
        "        print(flows_df.columns.tolist())\n",
        "    else:\n",
        "        print(\"\\nNo flows generated to display.\")\n",
        "\n",
        "    return flows_df,total_packets"
      ],
      "metadata": {
        "id": "7GkfYqDGRV1-"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for each pcap file in every attack\n",
        "# run the function\n",
        "# convert csv\n",
        "# move to attack_index\n",
        "\n",
        "for attack in attacks:\n",
        "  pcap_files = os.listdir(f'/content/{attack}')\n",
        "  for pcap_file in pcap_files:\n",
        "    file_name = pcap_file.split('.')[0]\n",
        "    pcap_file_name = f'{file_name}.pcap'\n",
        "    pcap_file_dir = f'/content/{attack}/'\n",
        "\n",
        "    csv_file_name = f'{file_name}.csv'\n",
        "    csv_file_dir = f'/content/{attack}_csv/'\n",
        "\n",
        "    index_file_name = f'{file_name}_index.csv'\n",
        "    index_file_dir = f'/content/{attack}_index/'\n",
        "\n",
        "    simulated_flows_df,total_packets = extract_flows_from_pcap(pcap_file_dir+pcap_file_name)\n",
        "    simulated_flows_df['Total_Packets'] = total_packets\n",
        "    simulated_flows_df.to_csv(index_file_dir+index_file_name, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCx91HegRlrc",
        "outputId": "2bbdfd01-6010-4b8b-bb0a-583b02785184"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading packets from /content/FTP-Bruteforce/bruteforce_ftp.pcap...\n",
            "Successfully read 49739 packets from /content/FTP-Bruteforce/bruteforce_ftp.pcap.\n",
            "Extracted 49739 valid packets from PCAP.\n",
            "\n",
            "Processing packets into flows (simulating CICFlowMeter logic)...\n",
            "\n",
            "Discovered 10397 flows.\n",
            "\n",
            "Head of the generated Flows DataFrame:\n",
            "                                Flow ID        Src IP  Src Port        Dst IP  \\\n",
            "0  192.168.1.70-192.168.1.90-36888-21-6  192.168.1.70     36888  192.168.1.90   \n",
            "1  192.168.1.70-192.168.1.90-36908-21-6  192.168.1.70     36908  192.168.1.90   \n",
            "2  192.168.1.70-192.168.1.90-36922-21-6  192.168.1.70     36922  192.168.1.90   \n",
            "3  192.168.1.70-192.168.1.90-36914-21-6  192.168.1.70     36914  192.168.1.90   \n",
            "4  192.168.1.70-192.168.1.90-36908-21-6  192.168.1.70     36908  192.168.1.90   \n",
            "\n",
            "   Dst Port  Protocol  Flow Duration (us)  Total Packets  Total Bytes  \\\n",
            "0        21         6               86427             18         1420   \n",
            "1        21         6               89750             18         1433   \n",
            "2        21         6               87135             18         1430   \n",
            "3        21         6               88690             18         1427   \n",
            "4        21         6                2402              2          132   \n",
            "\n",
            "   Fwd Packets  Bwd Packets  \\\n",
            "0            9            9   \n",
            "1            9            9   \n",
            "2            9            9   \n",
            "3            9            9   \n",
            "4            1            1   \n",
            "\n",
            "                                      Packet Indices  \\\n",
            "0  [0, 4, 9, 15, 20, 23, 27, 29, 36, 42, 44, 47, ...   \n",
            "1  [2, 7, 12, 17, 24, 31, 35, 39, 49, 53, 56, 62,...   \n",
            "2  [5, 10, 14, 19, 32, 33, 40, 41, 50, 51, 58, 63...   \n",
            "3  [3, 8, 13, 18, 25, 30, 34, 38, 45, 52, 60, 61,...   \n",
            "4                                         [157, 160]   \n",
            "\n",
            "                                   Packet Timestamps  \n",
            "0  [14315154879, 14315159002, 14315160660, 143151...  \n",
            "1  [14315156386, 14315159081, 14315162286, 143151...  \n",
            "2  [14315159030, 14315161884, 14315163852, 143151...  \n",
            "3  [14315157524, 14315160490, 14315163487, 143151...  \n",
            "4                         [14325210554, 14325212956]  \n",
            "\n",
            "Columns in the generated Flows DataFrame:\n",
            "['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Flow Duration (us)', 'Total Packets', 'Total Bytes', 'Fwd Packets', 'Bwd Packets', 'Packet Indices', 'Packet Timestamps']\n",
            "Reading packets from /content/FTP-Bruteforce/ftpbrute-ubuntu.pcap...\n",
            "Successfully read 20340 packets from /content/FTP-Bruteforce/ftpbrute-ubuntu.pcap.\n",
            "Extracted 20261 valid packets from PCAP.\n",
            "\n",
            "Processing packets into flows (simulating CICFlowMeter logic)...\n",
            "\n",
            "Discovered 1571 flows.\n",
            "\n",
            "Head of the generated Flows DataFrame:\n",
            "                                      Flow ID           Src IP  Src Port  \\\n",
            "0  192.168.159.159-192.168.159.160-21-44328-6  192.168.159.159        21   \n",
            "1  192.168.159.159-192.168.159.160-21-44328-6  192.168.159.159        21   \n",
            "2  192.168.159.159-192.168.159.160-21-44176-6  192.168.159.159        21   \n",
            "3  192.168.159.159-192.168.159.160-21-44192-6  192.168.159.159        21   \n",
            "4  192.168.159.159-192.168.159.160-21-44190-6  192.168.159.159        21   \n",
            "\n",
            "            Dst IP  Dst Port  Protocol  Flow Duration (us)  Total Packets  \\\n",
            "0  192.168.159.160     44328         6             6239786             18   \n",
            "1  192.168.159.160     44328         6              101682              4   \n",
            "2  192.168.159.160     44176         6             7105074             18   \n",
            "3  192.168.159.160     44192         6             7100945             18   \n",
            "4  192.168.159.160     44190         6             7105716             18   \n",
            "\n",
            "   Total Bytes  Fwd Packets  Bwd Packets  \\\n",
            "0         1379           10            8   \n",
            "1          278            4            0   \n",
            "2         1376           10            8   \n",
            "3         1381           10            8   \n",
            "4         1377           10            8   \n",
            "\n",
            "                                      Packet Indices  \\\n",
            "0  [58, 59, 101, 102, 103, 104, 125, 127, 182, 18...   \n",
            "1                               [258, 259, 260, 261]   \n",
            "2  [0, 1, 24, 25, 26, 28, 76, 92, 128, 129, 150, ...   \n",
            "3  [2, 3, 32, 33, 34, 35, 89, 100, 130, 131, 160,...   \n",
            "4  [4, 5, 36, 38, 40, 42, 90, 106, 132, 134, 164,...   \n",
            "\n",
            "                                   Packet Timestamps  \n",
            "0  [1748499869296364, 1748499869297794, 174849986...  \n",
            "1  [1748499875536571, 1748499875578345, 174849987...  \n",
            "2  [1748499869134839, 1748499869135644, 174849986...  \n",
            "3  [1748499869149855, 1748499869150990, 174849986...  \n",
            "4  [1748499869153770, 1748499869155088, 174849986...  \n",
            "\n",
            "Columns in the generated Flows DataFrame:\n",
            "['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Flow Duration (us)', 'Total Packets', 'Total Bytes', 'Fwd Packets', 'Bwd Packets', 'Packet Indices', 'Packet Timestamps']\n",
            "Reading packets from /content/FTP-Bruteforce/ftpbrute-kali.pcap...\n",
            "Successfully read 13910 packets from /content/FTP-Bruteforce/ftpbrute-kali.pcap.\n",
            "Extracted 13854 valid packets from PCAP.\n",
            "\n",
            "Processing packets into flows (simulating CICFlowMeter logic)...\n",
            "\n",
            "Discovered 1225 flows.\n",
            "\n",
            "Head of the generated Flows DataFrame:\n",
            "                                      Flow ID           Src IP  Src Port  \\\n",
            "0  192.168.159.159-192.168.159.160-21-60050-6  192.168.159.159        21   \n",
            "1  192.168.159.159-192.168.159.160-21-60056-6  192.168.159.159        21   \n",
            "2  192.168.159.159-192.168.159.160-21-60066-6  192.168.159.159        21   \n",
            "3  192.168.159.159-192.168.159.160-21-60070-6  192.168.159.159        21   \n",
            "4  192.168.159.159-192.168.159.160-21-60050-6  192.168.159.159        21   \n",
            "\n",
            "            Dst IP  Dst Port  Protocol  Flow Duration (us)  Total Packets  \\\n",
            "0  192.168.159.160     60050         6                 129              3   \n",
            "1  192.168.159.160     60056         6                 439              3   \n",
            "2  192.168.159.160     60066         6                   1              2   \n",
            "3  192.168.159.160     60070         6                   0              2   \n",
            "4  192.168.159.160     60050         6               61638              3   \n",
            "\n",
            "   Total Bytes  Fwd Packets  Bwd Packets Packet Indices  \\\n",
            "0          220            2            1      [2, 3, 4]   \n",
            "1          220            2            1      [5, 6, 7]   \n",
            "2          154            2            0        [9, 10]   \n",
            "3          154            2            0       [12, 13]   \n",
            "4          212            3            0    [8, 18, 19]   \n",
            "\n",
            "                                   Packet Timestamps  \n",
            "0  [1748499945131867, 1748499945131904, 174849994...  \n",
            "1  [1748499945166334, 1748499945166392, 174849994...  \n",
            "2               [1748499945182657, 1748499945182658]  \n",
            "3               [1748499945192061, 1748499945192061]  \n",
            "4  [1748499945172411, 1748499945233890, 174849994...  \n",
            "\n",
            "Columns in the generated Flows DataFrame:\n",
            "['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Flow Duration (us)', 'Total Packets', 'Total Bytes', 'Fwd Packets', 'Bwd Packets', 'Packet Indices', 'Packet Timestamps']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list filename_index.csv to have only indexcolumn\n",
        "for attack in attacks:\n",
        "  print('--------------------------------')\n",
        "  print(f\"CSV in {attack}_index\")\n",
        "  print('--------------------------------')\n",
        "  attack_indexs = os.listdir(f'/content/{attack}_index')\n",
        "  for attack_index in attack_indexs:\n",
        "    print(attack_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsXX-DxpSOpf",
        "outputId": "cfac60ca-2fdc-47bc-d924-6a4a1f400518"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "CSV in FTP-Bruteforce_index\n",
            "--------------------------------\n",
            "ftpbrute-kali_index.csv\n",
            ".ipynb_checkpoints\n",
            "bruteforce_ftp_index.csv\n",
            "ftpbrute-ubuntu_index.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ipaddress # For robust IP address comparison\n",
        "\n",
        "# --- Start: Helper Functions (from previous scripts, for self-contained use) ---\n",
        "\n",
        "def generate_flow_key(packet_components):\n",
        "    \"\"\"\n",
        "    Generates a unique key for a flow based on the 5-tuple,\n",
        "    mimicking CICFlowMeter's Java BasicPacketInfo.generateFlowId() logic\n",
        "    for canonicalizing IP addresses and ports.\n",
        "\n",
        "    This function uses the raw protocol number, matching BasicPacketInfo.java.\n",
        "    Any mapping of non-TCP/UDP/ICMP protocols to '0' happens *after* Flow ID generation\n",
        "    in CICFlowMeter's pipeline (e.g., for display in FlowFeature.featureValue2String),\n",
        "    and is NOT part of the Flow ID itself.\n",
        "\n",
        "    Args:\n",
        "        packet_components (tuple): A tuple containing (src_ip_str, dst_ip_str, src_port, dst_port, protocol_int)\n",
        "    Returns:\n",
        "        tuple: Canonical 5-tuple (normalized_src_ip, normalized_dst_ip, normalized_src_port, normalized_dst_port, normalized_protocol_int)\n",
        "    \"\"\"\n",
        "    src_ip_str, dst_ip_str, src_port, dst_port, protocol_int = packet_components\n",
        "\n",
        "    # Use ipaddress for robust IP comparison, mirroring Java's byte-by-byte comparison\n",
        "    try:\n",
        "        src_ip_obj = ipaddress.ip_address(src_ip_str)\n",
        "        dst_ip_obj = ipaddress.ip_address(dst_ip_str)\n",
        "    except ValueError:\n",
        "        # Fallback for invalid IPs if any, should not happen with valid PCAP data\n",
        "        return (src_ip_str, dst_ip_str, src_port, dst_port, protocol_int)\n",
        "\n",
        "\n",
        "    # Determine 'forward' based on IP comparison: canonical_src_ip will be the \"smaller\" IP\n",
        "    if src_ip_obj < dst_ip_obj:\n",
        "        normalized_src_ip = src_ip_str\n",
        "        normalized_dst_ip = dst_ip_str\n",
        "        normalized_src_port = src_port\n",
        "        normalized_dst_port = dst_port\n",
        "    elif dst_ip_obj < src_ip_obj:\n",
        "        # Swap IPs and their corresponding ports for normalization\n",
        "        normalized_src_ip = dst_ip_str\n",
        "        normalized_dst_ip = src_ip_str\n",
        "        normalized_src_port = dst_port\n",
        "        normalized_dst_port = src_port\n",
        "    else: # IPs are equal (e.g., multicast or broadcast)\n",
        "        # If IPs are the same, Java's logic does NOT swap ports based on IP.\n",
        "        # It keeps original src/dst IPs and ports as they are.\n",
        "        normalized_src_ip = src_ip_str\n",
        "        normalized_dst_ip = dst_ip_str\n",
        "        normalized_src_port = src_port\n",
        "        normalized_dst_port = dst_port\n",
        "\n",
        "    # The canonical 5-tuple key for the hash map\n",
        "    return (normalized_src_ip, normalized_dst_ip, normalized_src_port, normalized_dst_port, protocol_int)\n",
        "\n",
        "def parse_flow_id_string(flow_id_str):\n",
        "    \"\"\"\n",
        "    Parses a Flow ID string (e.g., 'IP1-IP2-Port1-Port2-Protocol') into its components.\n",
        "    Returns a tuple (src_ip, dst_ip, src_port, dst_port, protocol_int) or None if parsing fails.\n",
        "    \"\"\"\n",
        "    parts = flow_id_str.split('-')\n",
        "    if len(parts) == 5:\n",
        "        try:\n",
        "            return (parts[0], parts[1], int(parts[2]), int(parts[3]), int(parts[4]))\n",
        "        except ValueError:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def read_flows_to_dataframe(filepath: str, is_simulated_output: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Reads flow data from a CSV file into a Pandas DataFrame.\n",
        "    Adds a 'Canonical_Flow_ID' column for merging.\n",
        "    Parses 'Packet Indices' and 'Packet Timestamps' for simulated output.\n",
        "    This function keeps all original rows and does not deduplicate based on Canonical Flow ID.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the CSV file.\n",
        "        is_simulated_output (bool): True if reading our simulated output (with 'Packet Indices' column),\n",
        "                                    False if reading original CICFlowMeter output.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The loaded DataFrame with an added 'Canonical_Flow_ID' column.\n",
        "                      Returns an empty DataFrame if the file is not found or an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Create a new column with parsed components for canonicalization\n",
        "        df['Parsed_Flow_Components'] = df['Flow ID'].apply(parse_flow_id_string)\n",
        "\n",
        "        # Filter out rows where parsing failed\n",
        "        df = df.dropna(subset=['Parsed_Flow_Components'])\n",
        "\n",
        "        # Apply canonicalization to create 'Canonical_Flow_ID'\n",
        "        df['Canonical_Flow_ID'] = df['Parsed_Flow_Components'].apply(generate_flow_key).apply(lambda x: \"-\".join(map(str, x)))\n",
        "\n",
        "        # Clean up temporary column\n",
        "        df = df.drop(columns=['Parsed_Flow_Components'])\n",
        "\n",
        "        total_packets = 0\n",
        "        # Special handling for our simulated output's 'Packet Indices' and 'Packet Timestamps'\n",
        "        if is_simulated_output:\n",
        "            if 'Total_Packets' in df.columns:\n",
        "                total_packets = df['Total_Packets'].iloc[0]\n",
        "            if 'Packet Indices' in df.columns:\n",
        "                try:\n",
        "                    df['Packet Indices'] = df['Packet Indices'].apply(eval)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Could not parse 'Packet Indices' in {filepath}: {e}\")\n",
        "                    df['Packet Indices'] = [[]] * len(df) # Assign empty list on error\n",
        "            if 'Packet Timestamps' in df.columns:\n",
        "                try:\n",
        "                    df['Packet Timestamps'] = df['Packet Timestamps'].apply(eval)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Could not parse 'Packet Timestamps' in {filepath}: {e}\")\n",
        "                    df['Packet Timestamps'] = [[]] * len(df) # Assign empty list on error\n",
        "\n",
        "        print(f\"Successfully loaded {len(df)} flows from '{filepath}'.\")\n",
        "        return df,total_packets\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at '{filepath}'\")\n",
        "        return pd.DataFrame() # Return empty DataFrame on error\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading or processing CSV file '{filepath}': {e}\")\n",
        "        return pd.DataFrame() # Return empty DataFrame on error\n",
        "\n",
        "# --- End: Helper Functions ---\n",
        "\n",
        "def merge_flows_and_return_dataframe(simulated_df: pd.DataFrame, original_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Merges a DataFrame of simulated flows with a DataFrame of original CICFlowMeter flows\n",
        "    based on a canonical flow ID. It adds the 'Simulated Packet Indices' column to the\n",
        "    original flow data where a match is found.\n",
        "\n",
        "    Args:\n",
        "        simulated_df (pd.DataFrame): DataFrame containing flows generated by the simulation.\n",
        "                                     Expected to have 'Canonical_Flow_ID' and 'Packet Indices'.\n",
        "        original_df (pd.DataFrame): DataFrame containing flows from the original CICFlowMeter.\n",
        "                                    Expected to have 'Canonical_Flow_ID' and original flow features.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A merged DataFrame containing original CICFlowMeter features\n",
        "                      and 'Simulated Packet Indices' for matching flows.\n",
        "                      Returns an empty DataFrame if inputs are invalid.\n",
        "    \"\"\"\n",
        "    if simulated_df.empty or original_df.empty:\n",
        "        print(\"Cannot merge flows due to empty input DataFrames.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Perform a left merge on the 'Canonical_Flow_ID'\n",
        "    # Keep all rows from original_df, and add matching data from simulated_df.\n",
        "    # Select only 'Canonical_Flow_ID' and 'Packet Indices' from the simulated_df.\n",
        "    merged_df = pd.merge(\n",
        "        original_df,\n",
        "        simulated_df[['Canonical_Flow_ID', 'Packet Indices']],\n",
        "        on='Canonical_Flow_ID',\n",
        "        how='left',\n",
        "        suffixes=('_original', '_simulated')\n",
        "    )\n",
        "\n",
        "    # Rename the new column for clarity\n",
        "    merged_df = merged_df.rename(columns={\n",
        "        'Packet Indices': 'Simulated Packet Indices'\n",
        "    })\n",
        "\n",
        "    # Drop the 'Canonical_Flow_ID' column, as it's only for merging\n",
        "    merged_df = merged_df.drop(columns=['Canonical_Flow_ID'])\n",
        "\n",
        "    print(\"\\n--- Merged Flow Data (Original CICFlowMeter with Simulated Packet Indices) ---\")\n",
        "    print(f\"Total rows in merged DataFrame: {len(merged_df)}\")\n",
        "    print(\"Head of the merged DataFrame:\")\n",
        "    print(merged_df.head())\n",
        "\n",
        "    print(\"\\nColumns in the merged DataFrame:\")\n",
        "    print(merged_df.columns.tolist())\n",
        "\n",
        "    return merged_df"
      ],
      "metadata": {
        "id": "dXbxMCsERvrN"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for each pcap file in every attack\n",
        "# run the function\n",
        "# convert csv\n",
        "# move to attack_index\n",
        "\n",
        "for attack in attacks:\n",
        "  pcap_files = os.listdir(f'/content/{attack}')\n",
        "  for pcap_file in pcap_files:\n",
        "    file_name = pcap_file.split('.')[0]\n",
        "    pcap_file_name = f'{file_name}.pcap'\n",
        "    pcap_file_dir = f'/content/{attack}/'\n",
        "\n",
        "    csv_file_name = f'{file_name}_ISCX.csv'\n",
        "    csv_file_dir = f'/content/{attack}_csv/'\n",
        "\n",
        "    index_file_name = f'{file_name}_index.csv'\n",
        "    index_file_dir = f'/content/{attack}_index/'\n",
        "\n",
        "    simulated_csv_path = f'{index_file_dir}/{index_file_name}'\n",
        "    original_cic_csv_path = f'{csv_file_dir}/{csv_file_name}'\n",
        "\n",
        "    # Read the data from both CSVs into DataFrames using the helper function\n",
        "    simulated_df,total_packets = read_flows_to_dataframe(simulated_csv_path, is_simulated_output=True)\n",
        "    original_df,placeholder = read_flows_to_dataframe(original_cic_csv_path, is_simulated_output=False)\n",
        "\n",
        "    # Merge the flows and get the resulting DataFrame\n",
        "    final_merged_df = merge_flows_and_return_dataframe(simulated_df, original_df)\n",
        "    final_merged_df['Total_Packets'] = total_packets\n",
        "    final_merged_df.to_csv(f'{index_file_dir}/{index_file_name}', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWWktpjBVgnn",
        "outputId": "11f0ee58-e154-41aa-f270-70f6134f9b33"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 10397 flows from '/content/FTP-Bruteforce_index//bruteforce_ftp_index.csv'.\n",
            "Successfully loaded 6917 flows from '/content/FTP-Bruteforce_csv//bruteforce_ftp_ISCX.csv'.\n",
            "\n",
            "--- Merged Flow Data (Original CICFlowMeter with Simulated Packet Indices) ---\n",
            "Total rows in merged DataFrame: 25807\n",
            "Head of the merged DataFrame:\n",
            "                                Flow ID        Src IP  Src Port        Dst IP  \\\n",
            "0  192.168.1.70-192.168.1.90-36908-21-6  192.168.1.70     36908  192.168.1.90   \n",
            "1  192.168.1.70-192.168.1.90-36908-21-6  192.168.1.70     36908  192.168.1.90   \n",
            "2  192.168.1.70-192.168.1.90-36908-21-6  192.168.1.70     36908  192.168.1.90   \n",
            "3  192.168.1.70-192.168.1.90-36922-21-6  192.168.1.70     36922  192.168.1.90   \n",
            "4  192.168.1.70-192.168.1.90-36922-21-6  192.168.1.70     36922  192.168.1.90   \n",
            "\n",
            "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
            "0        21         6  01/01/1970 03:58:35       10054168            10   \n",
            "1        21         6  01/01/1970 03:58:35       10054168            10   \n",
            "2        21         6  01/01/1970 03:58:35       10054168            10   \n",
            "3        21         6  01/01/1970 03:58:35       10052811            10   \n",
            "4        21         6  01/01/1970 03:58:35       10052811            10   \n",
            "\n",
            "   Tot Bwd Pkts  ...  Active Mean  Active Std  Active Max  Active Min  \\\n",
            "0             9  ...          0.0         0.0         0.0         0.0   \n",
            "1             9  ...          0.0         0.0         0.0         0.0   \n",
            "2             9  ...          0.0         0.0         0.0         0.0   \n",
            "3             9  ...          0.0         0.0         0.0         0.0   \n",
            "4             9  ...          0.0         0.0         0.0         0.0   \n",
            "\n",
            "   Idle Mean  Idle Std  Idle Max  Idle Min     Label  \\\n",
            "0        0.0       0.0       0.0       0.0  No Label   \n",
            "1        0.0       0.0       0.0       0.0  No Label   \n",
            "2        0.0       0.0       0.0       0.0  No Label   \n",
            "3        0.0       0.0       0.0       0.0  No Label   \n",
            "4        0.0       0.0       0.0       0.0  No Label   \n",
            "\n",
            "                            Simulated Packet Indices  \n",
            "0  [2, 7, 12, 17, 24, 31, 35, 39, 49, 53, 56, 62,...  \n",
            "1                                         [157, 160]  \n",
            "2                                              [163]  \n",
            "3  [5, 10, 14, 19, 32, 33, 40, 41, 50, 51, 58, 63...  \n",
            "4                                         [158, 161]  \n",
            "\n",
            "[5 rows x 85 columns]\n",
            "\n",
            "Columns in the merged DataFrame:\n",
            "['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label', 'Simulated Packet Indices']\n",
            "Successfully loaded 1571 flows from '/content/FTP-Bruteforce_index//ftpbrute-ubuntu_index.csv'.\n",
            "Successfully loaded 1462 flows from '/content/FTP-Bruteforce_csv//ftpbrute-ubuntu_ISCX.csv'.\n",
            "\n",
            "--- Merged Flow Data (Original CICFlowMeter with Simulated Packet Indices) ---\n",
            "Total rows in merged DataFrame: 4389\n",
            "Head of the merged DataFrame:\n",
            "                                      Flow ID           Src IP  Src Port  \\\n",
            "0  192.168.159.159-192.168.159.160-21-44328-6  192.168.159.159        21   \n",
            "1  192.168.159.159-192.168.159.160-21-44328-6  192.168.159.159        21   \n",
            "2  192.168.159.159-192.168.159.160-21-44328-6  192.168.159.159        21   \n",
            "3  192.168.159.159-192.168.159.160-21-44328-6  192.168.159.160     44328   \n",
            "4  192.168.159.159-192.168.159.160-21-44328-6  192.168.159.160     44328   \n",
            "\n",
            "            Dst IP  Dst Port  Protocol            Timestamp  Flow Duration  \\\n",
            "0  192.168.159.160     44328         6  29/05/2025 06:24:29        6239786   \n",
            "1  192.168.159.160     44328         6  29/05/2025 06:24:29        6239786   \n",
            "2  192.168.159.160     44328         6  29/05/2025 06:24:29        6239786   \n",
            "3  192.168.159.159        21         6  29/05/2025 06:24:35         101682   \n",
            "4  192.168.159.159        21         6  29/05/2025 06:24:35         101682   \n",
            "\n",
            "   Tot Fwd Pkts  Tot Bwd Pkts  ...  Active Mean  Active Std  Active Max  \\\n",
            "0            10             8  ...          0.0         0.0         0.0   \n",
            "1            10             8  ...          0.0         0.0         0.0   \n",
            "2            10             8  ...          0.0         0.0         0.0   \n",
            "3             4             0  ...          0.0         0.0         0.0   \n",
            "4             4             0  ...          0.0         0.0         0.0   \n",
            "\n",
            "   Active Min  Idle Mean  Idle Std  Idle Max  Idle Min     Label  \\\n",
            "0         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "1         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "2         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "3         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "4         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "\n",
            "                            Simulated Packet Indices  \n",
            "0  [58, 59, 101, 102, 103, 104, 125, 127, 182, 18...  \n",
            "1                               [258, 259, 260, 261]  \n",
            "2                                         [262, 263]  \n",
            "3  [58, 59, 101, 102, 103, 104, 125, 127, 182, 18...  \n",
            "4                               [258, 259, 260, 261]  \n",
            "\n",
            "[5 rows x 85 columns]\n",
            "\n",
            "Columns in the merged DataFrame:\n",
            "['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label', 'Simulated Packet Indices']\n",
            "Successfully loaded 1225 flows from '/content/FTP-Bruteforce_index//ftpbrute-kali_index.csv'.\n",
            "Successfully loaded 1217 flows from '/content/FTP-Bruteforce_csv//ftpbrute-kali_ISCX.csv'.\n",
            "\n",
            "--- Merged Flow Data (Original CICFlowMeter with Simulated Packet Indices) ---\n",
            "Total rows in merged DataFrame: 3659\n",
            "Head of the merged DataFrame:\n",
            "                                      Flow ID           Src IP  Src Port  \\\n",
            "0  192.168.159.159-192.168.159.160-21-60050-6  192.168.159.159        21   \n",
            "1  192.168.159.159-192.168.159.160-21-60050-6  192.168.159.159        21   \n",
            "2  192.168.159.159-192.168.159.160-21-60050-6  192.168.159.159        21   \n",
            "3  192.168.159.159-192.168.159.160-21-60056-6  192.168.159.159        21   \n",
            "4  192.168.159.159-192.168.159.160-21-60056-6  192.168.159.159        21   \n",
            "\n",
            "            Dst IP  Dst Port  Protocol            Timestamp  Flow Duration  \\\n",
            "0  192.168.159.160     60050         6  29/05/2025 06:25:45            129   \n",
            "1  192.168.159.160     60050         6  29/05/2025 06:25:45            129   \n",
            "2  192.168.159.160     60050         6  29/05/2025 06:25:45            129   \n",
            "3  192.168.159.160     60056         6  29/05/2025 06:25:45            439   \n",
            "4  192.168.159.160     60056         6  29/05/2025 06:25:45            439   \n",
            "\n",
            "   Tot Fwd Pkts  Tot Bwd Pkts  ...  Active Mean  Active Std  Active Max  \\\n",
            "0             2             1  ...          0.0         0.0         0.0   \n",
            "1             2             1  ...          0.0         0.0         0.0   \n",
            "2             2             1  ...          0.0         0.0         0.0   \n",
            "3             2             1  ...          0.0         0.0         0.0   \n",
            "4             2             1  ...          0.0         0.0         0.0   \n",
            "\n",
            "   Active Min  Idle Mean  Idle Std  Idle Max  Idle Min     Label  \\\n",
            "0         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "1         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "2         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "3         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "4         0.0        0.0       0.0       0.0       0.0  No Label   \n",
            "\n",
            "   Simulated Packet Indices  \n",
            "0                 [2, 3, 4]  \n",
            "1               [8, 18, 19]  \n",
            "2                  [21, 22]  \n",
            "3                 [5, 6, 7]  \n",
            "4              [15, 33, 34]  \n",
            "\n",
            "[5 rows x 85 columns]\n",
            "\n",
            "Columns in the merged DataFrame:\n",
            "['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label', 'Simulated Packet Indices']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "eUsuVyYqX6Ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define function for model loading\n",
        "import joblib\n",
        "def load_model(model_name):\n",
        "  model_path = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/' + model_name\n",
        "  model = joblib.load(model_path)\n",
        "  return model\n",
        "\n",
        "# model = load_model(model_name)\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "i82N37k3Xo6x"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model_name = 'RandomForest400IntPortCIC1718-2.pkl'\n",
        "model = load_model(model_name)\n",
        "print(model)\n",
        "# attacks = model.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWXyPNASX5To",
        "outputId": "538be8af-bb0e-40d2-ed8d-8341592b4921"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function for df preprocessing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "def map_port(port):\n",
        "    if port == 21:\n",
        "        return 1  # FTP\n",
        "    elif port == 22:\n",
        "        return 2  # SSH\n",
        "    elif port == 53:\n",
        "        return 3  # DNS\n",
        "    elif port == 80:\n",
        "        return 4  # HTTP\n",
        "    elif port == 443:\n",
        "        return 5  # HTTPS\n",
        "    else:\n",
        "        return 6  # Other\n",
        "\n",
        "def preprocess_dataframe(df):\n",
        "    original_indices = set(df.index)\n",
        "\n",
        "    # replace space in columns name with underscore\n",
        "    df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
        "\n",
        "    # drop objects type columns\n",
        "    columns_to_drop = [\n",
        "        'Flow_ID','Src_IP','Dst_IP','Src_Port','Protocol','Timestamp','Label'\n",
        "    ]\n",
        "\n",
        "    df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "    # remove rows with missing and infinite values\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df = df.dropna()\n",
        "\n",
        "    # map destination port to 1-6 numbers\n",
        "    df['Dst_Port'] = df['Dst_Port'].apply(map_port)\n",
        "\n",
        "    return df\n",
        "\n",
        "# preprocess_dataframe(df)"
      ],
      "metadata": {
        "id": "STzSwfrBX8Y1"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_label(labels):\n",
        "    if all(label == 'Benign' for label in labels):\n",
        "        return 'Benign'\n",
        "    else:\n",
        "        # Return unique non-Benign labels as a list (or you can join them if you want)\n",
        "        non_benign = list(set(label for label in labels if label != 'Benign'))\n",
        "        # If you want just one label instead of list, you can use: non_benign[0]\n",
        "        return non_benign if len(non_benign) > 1 else non_benign[0]\n",
        "\n",
        "for attack in attacks:\n",
        "  pcap_files = os.listdir(f'/content/{attack}')\n",
        "  for pcap_file in pcap_files:\n",
        "    file_name = pcap_file.split('.')[0]\n",
        "    pcap_file_name = f'{file_name}.pcap'\n",
        "    pcap_file_dir = f'/content/{attack}/'\n",
        "\n",
        "    csv_file_name = f'{file_name}_ISCX.csv'\n",
        "    csv_file_dir = f'/content/{attack}_csv/'\n",
        "\n",
        "    index_file_name = f'{file_name}_index.csv'\n",
        "    index_file_dir = f'/content/{attack}_index/'\n",
        "\n",
        "    prediction_file_name = f'{file_name}_prediction.csv'\n",
        "    prediction_file_dir = f'/content/{attack}_prediction/'\n",
        "\n",
        "    df = pd.read_csv(f'{index_file_dir}/{index_file_name}')\n",
        "    df = preprocess_dataframe(df)\n",
        "\n",
        "    total_packets = df['Total_Packets'].iloc[0]\n",
        "    df = df.drop(columns=['Total_Packets'])\n",
        "    # print(f\"{pcap_file_name} : {total_packets}\")\n",
        "\n",
        "    df_packet_index = df['Simulated_Packet_Indices']\n",
        "    df_packet_index = df_packet_index.apply(ast.literal_eval)\n",
        "\n",
        "    df = df.drop(columns=['Simulated_Packet_Indices'])\n",
        "    df_prediction = model.predict(df)\n",
        "\n",
        "    df_prediction = pd.DataFrame({\n",
        "    'Packet_Indices': df_packet_index,\n",
        "    'Label': df_prediction\n",
        "    })\n",
        "\n",
        "    df_prediction = df_prediction.explode('Packet_Indices').reset_index(drop=True)\n",
        "\n",
        "    # after edit\n",
        "    df_prediction = df_prediction.groupby('Packet_Indices')['Label'].apply(list).reset_index()\n",
        "    df_prediction['Chosen_Label'] = df_prediction['Label'].apply(choose_label)\n",
        "\n",
        "    full_indices = set(range(1, total_packets + 1))\n",
        "    existing_indices = set(df_prediction['Packet_Indices'])\n",
        "    missing_indices = sorted(full_indices - existing_indices)\n",
        "\n",
        "    df_missing = pd.DataFrame({\n",
        "    'Packet_Indices': missing_indices,\n",
        "    'Label': [['Benign']] * len(missing_indices),\n",
        "    'Chosen_Label': ['Benign'] * len(missing_indices),\n",
        "    })\n",
        "\n",
        "    df_prediction = pd.concat([df_prediction, df_missing], ignore_index=True)\n",
        "\n",
        "    df_prediction.sort_values(by='Packet_Indices', inplace=True)\n",
        "    df_prediction.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    os.makedirs(prediction_file_dir, exist_ok=True)\n",
        "    df_prediction.to_csv(f'{prediction_file_dir}/{prediction_file_name}', index=False)"
      ],
      "metadata": {
        "id": "35mrjNeMYBCn"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for attack in attacks:\n",
        "  pcap_files = os.listdir(f'/content/{attack}')\n",
        "  for pcap_file in pcap_files:\n",
        "    file_name = pcap_file.split('.')[0]\n",
        "    pcap_file_name = f'{file_name}.pcap'\n",
        "    pcap_file_dir = f'/content/{attack}/'\n",
        "\n",
        "    csv_file_name = f'{file_name}_ISCX.csv'\n",
        "    csv_file_dir = f'/content/{attack}_csv/'\n",
        "\n",
        "    index_file_name = f'{file_name}_index.csv'\n",
        "    index_file_dir = f'/content/{attack}_index/'\n",
        "\n",
        "    prediction_file_name = f'{file_name}_prediction.csv'\n",
        "    prediction_file_dir = f'/content/{attack}_prediction/'\n",
        "\n",
        "    df = pd.read_csv(f'{prediction_file_dir}/{prediction_file_name}')\n",
        "    print(df['Chosen_Label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdVopIgJsgyF",
        "outputId": "4bc9d84b-b069-4d80-bc90-b67215806474"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen_Label\n",
            "Benign    49740\n",
            "Name: count, dtype: int64\n",
            "Chosen_Label\n",
            "FTP-Bruteforce    17588\n",
            "Benign             2753\n",
            "Name: count, dtype: int64\n",
            "Chosen_Label\n",
            "FTP-Bruteforce    13684\n",
            "Benign              227\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dominant_label(label_series):\n",
        "    counts = label_series.value_counts()\n",
        "\n",
        "    if len(counts) == 1 and 'Benign' in counts:\n",
        "        return 'Benign'\n",
        "\n",
        "    # Drop 'Benign' and get the most common remaining label\n",
        "    counts = counts.drop('Benign', errors='ignore')\n",
        "    if not counts.empty:\n",
        "        return counts.idxmax()\n",
        "    else:\n",
        "        return 'Benign'\n",
        "\n",
        "for attack in attacks:\n",
        "    pcap_files = os.listdir(f'/content/{attack}')\n",
        "    for pcap_file in pcap_files:\n",
        "        file_name = pcap_file.split('.')[0]\n",
        "\n",
        "        pcap_file_name = f'{file_name}.pcap'\n",
        "\n",
        "        prediction_file_name = f'{file_name}_prediction.csv'\n",
        "        prediction_file_dir = f'/content/{attack}_prediction/'\n",
        "        prediction_csv_path = f'{prediction_file_dir}/{prediction_file_name}'\n",
        "\n",
        "        final_pcap_label = get_dominant_label(df['Chosen_Label'])\n",
        "        print(f\"{pcap_file_name}: {final_pcap_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaZzbHqktyYx",
        "outputId": "f62b2ef0-a239-40bb-f106-ba36484e23b1"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bruteforce_ftp.pcap: FTP-Bruteforce\n",
            "ftpbrute-ubuntu.pcap: FTP-Bruteforce\n",
            "ftpbrute-kali.pcap: FTP-Bruteforce\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "all_true_labels = []\n",
        "all_predicted_labels = []\n",
        "\n",
        "for attack in attacks:\n",
        "    pcap_files = os.listdir(f'/content/{attack}')\n",
        "    for pcap_file in pcap_files:\n",
        "        file_name = pcap_file.split('.')[0]\n",
        "        prediction_file_name = f'{file_name}_prediction.csv'\n",
        "        prediction_file_dir = f'/content/{attack}_prediction/'\n",
        "        prediction_csv_path = f'{prediction_file_dir}/{prediction_file_name}'\n",
        "\n",
        "        try:\n",
        "            df_prediction = pd.read_csv(prediction_csv_path)\n",
        "            # The true label for all packets in this file is the 'attack' name\n",
        "            true_label = attack\n",
        "\n",
        "            # Collect the predicted label for each packet from 'Chosen_Label'\n",
        "            predicted_labels = df_prediction['Chosen_Label'].tolist()\n",
        "\n",
        "            # Extend our master lists\n",
        "            all_true_labels.extend([true_label] * len(predicted_labels))\n",
        "            all_predicted_labels.extend(predicted_labels)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Prediction file not found for {pcap_file}: {prediction_csv_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing prediction file {prediction_csv_path}: {e}\")\n",
        "\n",
        "# Now, print the classification report using the collected true and predicted labels\n",
        "if all_true_labels and all_predicted_labels:\n",
        "    print(\"\\n--- Classification Report ---\")\n",
        "    # Ensure both lists are of the same length\n",
        "    if len(all_true_labels) == len(all_predicted_labels):\n",
        "        print(classification_report(all_true_labels, all_predicted_labels, zero_division=0))\n",
        "    else:\n",
        "        print(\"Error: Mismatch in the number of true labels and predicted labels.\")\n",
        "else:\n",
        "    print(\"\\nNo data collected to generate a classification report.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCVJt-YJtA3s",
        "outputId": "9add6a65-d520-4897-8b7c-6f7e9ecb07d4"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Classification Report ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "        Benign       0.00      0.00      0.00         0\n",
            "FTP-Bruteforce       1.00      0.37      0.54     83992\n",
            "\n",
            "      accuracy                           0.37     83992\n",
            "     macro avg       0.50      0.19      0.27     83992\n",
            "  weighted avg       1.00      0.37      0.54     83992\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# archivae again"
      ],
      "metadata": {
        "id": "h91XlaLdRUbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up for mapping function\n",
        "\n",
        "# --- Setup and Imports (Run this cell first in Colab) ---\n",
        "# Install Scapy and Pandas (output redirected to avoid clutter)\n",
        "!pip install scapy pandas numpy > /content/log.txt\n",
        "\n",
        "# Import necessary libraries\n",
        "from scapy.all import PcapReader, IP, TCP, UDP, ICMP\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ipaddress\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import struct\n",
        "import traceback # For detailed error logging\n",
        "\n",
        "# Define constants based on CICFlowMeter's declaration\n",
        "# These are in microseconds based on the provided Java code\n",
        "FLOW_TIMEOUT = 120_000_000 # 120 seconds = 2 minutes\n",
        "FLOW_ACTIVITY_TIMEOUT = 5_000_000 # 5 seconds\n",
        "\n",
        "print(\"Environment setup complete. Libraries installed and imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF9qK2eYOg6b",
        "outputId": "c74f6ff7-1475-4ffd-d042-3e26e33dad73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment setup complete. Libraries installed and imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Classes (PacketInfo, SimulatedFlow, FlowAggregator) ---\n",
        "# These classes encapsulate the core logic for packet and flow handling.\n",
        "# They are defined globally so they can be reused.\n",
        "\n",
        "class PacketInfo:\n",
        "    def __init__(self, packet_index, timestamp_us, src_ip, dst_ip, src_port, dst_port, protocol, tcp_flags=0):\n",
        "        self.packet_index = packet_index\n",
        "        self.timestamp_us = timestamp_us # Timestamp in microseconds\n",
        "        self.src_ip = src_ip\n",
        "        self.dst_ip = dst_ip\n",
        "        self.src_port = src_port\n",
        "        self.dst_port = dst_port\n",
        "        self.protocol = protocol # e.g., 6 for TCP, 17 for UDP, 1 for ICMP\n",
        "        self.tcp_flags = tcp_flags\n",
        "\n",
        "        self.src_ip_bytes = self._ip_to_bytes(src_ip)\n",
        "        self.dst_ip_bytes = self._ip_to_bytes(dst_ip)\n",
        "\n",
        "        self.flow_id = self.generate_flow_id()\n",
        "\n",
        "    def _ip_to_bytes(self, ip_str):\n",
        "        \"\"\"Converts an IP address string to a byte array.\"\"\"\n",
        "        try:\n",
        "            return bytes(ipaddress.ip_address(ip_str).packed)\n",
        "        except ValueError:\n",
        "            return b''\n",
        "\n",
        "    def has_flag_fin(self):\n",
        "        \"\"\"Check if TCP FIN flag is set.\"\"\"\n",
        "        return (self.protocol == 6) and (self.tcp_flags & 0x01) # FIN flag is 0x01\n",
        "\n",
        "    def generate_flow_id(self):\n",
        "        \"\"\"\n",
        "        Replicates CICFlowMeter's generateFlowId logic based on 5-tuple.\n",
        "        This ensures bidirectional flows have a canonical ID.\n",
        "        \"\"\"\n",
        "        forward = True\n",
        "        src_bytes = self.src_ip_bytes\n",
        "        dst_bytes = self.dst_ip_bytes\n",
        "\n",
        "        if src_bytes and dst_bytes and len(src_bytes) == len(dst_bytes):\n",
        "            for i in range(len(src_bytes)):\n",
        "                if src_bytes[i] != dst_bytes[i]:\n",
        "                    if src_bytes[i] > dst_bytes[i]:\n",
        "                        forward = False\n",
        "                    break\n",
        "\n",
        "        if forward:\n",
        "            flow_id_str = f\"{self.src_ip}-{self.dst_ip}-{self.src_port}-{self.dst_port}-{self.protocol}\"\n",
        "        else:\n",
        "            flow_id_str = f\"{self.dst_ip}-{self.src_ip}-{self.dst_port}-{self.src_port}-{self.protocol}\"\n",
        "        return flow_id_str\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"PacketInfo(idx={self.packet_index}, ts={self.timestamp_us}, \"\n",
        "                f\"flow_id='{self.flow_id}', proto={self.protocol}, \"\n",
        "                f\"src={self.src_ip}:{self.src_port}, dst={self.dst_ip}:{self.dst_port})\")\n",
        "\n",
        "class SimulatedFlow:\n",
        "    def __init__(self, first_packet: PacketInfo):\n",
        "        self.flow_id_string = first_packet.flow_id\n",
        "        self.flow_start_time_us = first_packet.timestamp_us\n",
        "        self.flow_last_seen_us = first_packet.timestamp_us\n",
        "        self.packet_indices = []\n",
        "\n",
        "        self.initial_src_ip_bytes = first_packet.src_ip_bytes\n",
        "\n",
        "        self.add_packet_index(first_packet.packet_index)\n",
        "\n",
        "        self.start_active_time_us = first_packet.timestamp_us\n",
        "        self.end_active_time_us = first_packet.timestamp_us\n",
        "\n",
        "    def add_packet_index(self, packet_index: int):\n",
        "        \"\"\"Adds a packet index to the flow.\"\"\"\n",
        "        self.packet_indices.append(packet_index)\n",
        "\n",
        "    def update_flow_timestamps(self, current_timestamp_us: int):\n",
        "        \"\"\"Updates the flow's overall last seen timestamp.\"\"\"\n",
        "        self.flow_last_seen_us = current_timestamp_us\n",
        "\n",
        "    def update_active_idle_time(self, current_timestamp_us: int, threshold_us: int):\n",
        "        \"\"\"Simulates BasicFlow's updateActiveIdleTime for feature tracking.\"\"\"\n",
        "        if current_timestamp_us - self.end_active_time_us > threshold_us:\n",
        "            self.start_active_time_us = current_timestamp_us\n",
        "            self.end_active_time_us = current_timestamp_us\n",
        "        else:\n",
        "            self.end_active_time_us = current_timestamp_us\n",
        "\n",
        "    def get_duration_us(self):\n",
        "        \"\"\"Calculates the total duration of the flow in microseconds.\"\"\"\n",
        "        return self.flow_last_seen_us - self.flow_start_time_us\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"SimulatedFlow(id='{self.flow_id_string}', \"\n",
        "                f\"start_ts={self.flow_start_time_us}, end_ts={self.flow_last_seen_us}, \"\n",
        "                f\"packets={len(self.packet_indices)}, \"\n",
        "                f\"indices={self.packet_indices[:5]}...{self.packet_indices[-5:] if len(self.packet_indices) > 5 else ''})\")\n",
        "\n",
        "class FlowAggregator:\n",
        "    def __init__(self, flow_timeout_us, flow_activity_timeout_us):\n",
        "        self.current_flows = {} # {flow_id_string: SimulatedFlow_object}\n",
        "        self.finished_flows = {} # {flow_id_string: SimulatedFlow_object} (using flow_id_string as key for direct lookup)\n",
        "        self.flow_timeout_us = flow_timeout_us\n",
        "        self.flow_activity_timeout_us = flow_activity_timeout_us\n",
        "\n",
        "    def add_packet(self, packet: PacketInfo):\n",
        "        if not packet:\n",
        "            return\n",
        "\n",
        "        current_timestamp = packet.timestamp_us\n",
        "        flow_id_string = packet.flow_id\n",
        "\n",
        "        if flow_id_string in self.current_flows:\n",
        "            flow = self.current_flows[flow_id_string]\n",
        "\n",
        "            # --- CICFlowMeter's Flow Termination Logic ---\n",
        "            if current_timestamp - flow.flow_start_time_us > self.flow_timeout_us:\n",
        "                if len(flow.packet_indices) > 1:\n",
        "                    self.finished_flows[flow_id_string] = flow\n",
        "                del self.current_flows[flow_id_string]\n",
        "                self.current_flows[flow_id_string] = SimulatedFlow(packet)\n",
        "\n",
        "            elif packet.has_flag_fin():\n",
        "                flow.add_packet_index(packet.packet_index)\n",
        "                flow.update_flow_timestamps(current_timestamp)\n",
        "                if len(flow.packet_indices) > 1:\n",
        "                    self.finished_flows[flow_id_string] = flow\n",
        "                del self.current_flows[flow_id_string]\n",
        "\n",
        "            else:\n",
        "                flow.update_active_idle_time(current_timestamp, self.flow_activity_timeout_us)\n",
        "                flow.add_packet_index(packet.packet_index)\n",
        "                flow.update_flow_timestamps(current_timestamp)\n",
        "\n",
        "        else:\n",
        "            self.current_flows[flow_id_string] = SimulatedFlow(packet)\n",
        "\n",
        "    def finish_all_remaining_flows(self):\n",
        "        \"\"\"Moves all flows still in current_flows to finished_flows.\"\"\"\n",
        "        for flow_id_string, flow in list(self.current_flows.items()):\n",
        "            if len(flow.packet_indices) > 1:\n",
        "                self.finished_flows[flow_id_string] = flow\n",
        "            del self.current_flows[flow_id_string]\n",
        "\n",
        "    def get_simulated_flow_data(self):\n",
        "        \"\"\"\n",
        "        Returns a dictionary mapping CICFlowMeter's Flow ID string to list of packet indices.\n",
        "        \"\"\"\n",
        "        all_simulated_flows = {**self.finished_flows, **self.current_flows}\n",
        "\n",
        "        mapping_dict = {}\n",
        "        for flow_id_str, flow_obj in all_simulated_flows.items():\n",
        "            if len(flow_obj.packet_indices) >= 1: # Only include flows with > 1 packet\n",
        "                mapping_dict[flow_id_str] = flow_obj.packet_indices\n",
        "        return mapping_dict\n",
        "\n",
        "\n",
        "\n",
        "### **Main Function: `process_pcap_and_map_flows`**\n",
        "\n",
        "def process_pcap_and_map_flows(attack: str, name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Processes a PCAP file, simulates CICFlowMeter's flow generation,\n",
        "    and merges the resulting packet-to-flow mapping with an existing\n",
        "    CICFlowMeter output CSV.\n",
        "\n",
        "    Args:\n",
        "        attack (str): The name of the attack directory (e.g., \"FTPBruteforce\").\n",
        "        name (str): The base name of the PCAP and CICFlowMeter output files\n",
        "                    (e.g., \"ftpbrute-ubuntu\").\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The merged DataFrame with a 'Packet Indices Mapped' column,\n",
        "                      or None if an error occurs.\n",
        "    \"\"\"\n",
        "    # Construct file paths\n",
        "    pcap_file_path = f\"{attack}/{name}.pcap\"\n",
        "    cicflowmeter_output_path = f\"/content/{attack}_csv/{name}_ISCX.csv\"\n",
        "    output_merged_csv_path = f\"/content/{attack}_index/{name}_index.csv\"\n",
        "\n",
        "    print(f\"\\n--- Starting processing for {attack}/{name} ---\")\n",
        "    print(f\"PCAP: {pcap_file_path}\")\n",
        "    print(f\"CICFlowMeter Output: {cicflowmeter_output_path}\")\n",
        "    print(f\"Merged Output: {output_merged_csv_path}\")\n",
        "\n",
        "    flow_aggregator = FlowAggregator(FLOW_TIMEOUT, FLOW_ACTIVITY_TIMEOUT)\n",
        "\n",
        "    print(f\"\\nStarting PCAP processing: {pcap_file_path}\")\n",
        "    packet_count = 0\n",
        "    try:\n",
        "        for pkt in PcapReader(pcap_file_path):\n",
        "            packet_count += 1\n",
        "\n",
        "            src_ip = None\n",
        "            dst_ip = None\n",
        "            src_port = 0\n",
        "            dst_port = 0\n",
        "            protocol = None\n",
        "            tcp_flags = 0\n",
        "\n",
        "            if IP in pkt:\n",
        "                src_ip = pkt[IP].src\n",
        "                dst_ip = pkt[IP].dst\n",
        "                protocol = pkt[IP].proto\n",
        "\n",
        "                if TCP in pkt:\n",
        "                    src_port = pkt[TCP].sport\n",
        "                    dst_port = pkt[TCP].dport\n",
        "                    tcp_flags = pkt[TCP].flags\n",
        "                elif UDP in pkt:\n",
        "                    src_port = pkt[UDP].sport\n",
        "                    dst_port = pkt[UDP].dport\n",
        "                elif ICMP in pkt:\n",
        "                    pass\n",
        "\n",
        "                timestamp_us = int(pkt.time * 1_000_000)\n",
        "\n",
        "                if src_ip and dst_ip and protocol is not None:\n",
        "                    p_info = PacketInfo(\n",
        "                        packet_index=packet_count,\n",
        "                        timestamp_us=timestamp_us,\n",
        "                        src_ip=src_ip,\n",
        "                        dst_ip=dst_ip,\n",
        "                        src_port=src_port,\n",
        "                        dst_port=dst_port,\n",
        "                        protocol=protocol,\n",
        "                        tcp_flags=tcp_flags\n",
        "                    )\n",
        "                    flow_aggregator.add_packet(p_info)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: PCAP file not found at {pcap_file_path}.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during PCAP processing for {pcap_file_path}: {e}\")\n",
        "        print(f\"Error occurred at packet_count: {packet_count}\")\n",
        "        print(traceback.format_exc())\n",
        "        return None\n",
        "\n",
        "    flow_aggregator.finish_all_remaining_flows()\n",
        "    simulated_flow_data = flow_aggregator.get_simulated_flow_data()\n",
        "\n",
        "    print(f\"\\nPCAP processing complete. Processed {packet_count} packets.\")\n",
        "    print(f\"Simulated {len(simulated_flow_data)} flows with more than 1 packet.\")\n",
        "\n",
        "    print(f\"\\nLoading CICFlowMeter output from: {cicflowmeter_output_path}\")\n",
        "    try:\n",
        "        cic_df = pd.read_csv(cicflowmeter_output_path)\n",
        "\n",
        "        # Standardize the 'Flow ID' column name and type for merging\n",
        "        if 'Flow ID' in cic_df.columns:\n",
        "            cic_df.rename(columns={'Flow ID': 'Flow ID'}, inplace=True)\n",
        "        elif 'FlowId' in cic_df.columns:\n",
        "            cic_df.rename(columns={'FlowId': 'Flow ID'}, inplace=True)\n",
        "        else:\n",
        "            print(\"Error: 'Flow ID' or 'FlowId' column not found in CICFlowMeter CSV.\")\n",
        "            return None\n",
        "\n",
        "        cic_df['Flow ID'] = cic_df['Flow ID'].astype(str)\n",
        "\n",
        "        packet_indices_series = pd.Series(simulated_flow_data)\n",
        "\n",
        "        cic_df['Packet Indices Mapped'] = cic_df['Flow ID'].apply(lambda x: packet_indices_series.get(x, []))\n",
        "        # cic_df['Packet Indices Mapped'] = cic_df['Packet Indices Mapped'].apply(lambda x: f\"[{','.join(map(str, x))}]\")\n",
        "\n",
        "        print(\"\\nMerged DataFrame head (showing Flow ID, Packet Count, and Mapped Indices):\")\n",
        "        display_cols = ['Flow ID', 'Packet Indices Mapped']\n",
        "        packet_count_col_name = None\n",
        "        for col in [' Packet Count', 'Packet Count', 'Total Fwd Packets', 'Total Backward Packets', 'Total Packets']:\n",
        "            if col in cic_df.columns:\n",
        "                packet_count_col_name = col\n",
        "                break\n",
        "\n",
        "        if packet_count_col_name:\n",
        "            display_cols.insert(1, packet_count_col_name)\n",
        "\n",
        "        print(cic_df[display_cols].head())\n",
        "\n",
        "        cic_df.to_csv(output_merged_csv_path, index=False)\n",
        "        print(f\"\\nUpdated CICFlowMeter output with packet indices saved to: {output_merged_csv_path}\")\n",
        "\n",
        "        print(\"\\n--- Verification ---\")\n",
        "        total_cic_flows = len(cic_df)\n",
        "        mapped_flows_count = cic_df[cic_df['Packet Indices Mapped'] != '[]'].shape[0]\n",
        "        unmapped_flows_count = total_cic_flows - mapped_flows_count\n",
        "\n",
        "        print(f\"Total flows in CICFlowMeter output: {total_cic_flows}\")\n",
        "        print(f\"Flows successfully mapped to packet indices: {mapped_flows_count}\")\n",
        "        print(f\"Flows in CICFlowMeter output that could NOT be mapped: {unmapped_flows_count}\")\n",
        "\n",
        "        if packet_count_col_name:\n",
        "            print(\"\\nSample of Unmapped Flows:\")\n",
        "            unmapped_df = cic_df[cic_df['Packet Indices Mapped'] == '[]']\n",
        "            print(unmapped_df[['Flow ID', packet_count_col_name]].head())\n",
        "        else:\n",
        "            print(\"\\nSkipping sample of unmapped flows as 'Packet Count' column was not found.\")\n",
        "\n",
        "        # make the cic_df only return the packet_indices mapped of that csv\n",
        "        cic_df = cic_df['Packet Indices Mapped']\n",
        "        return cic_df,packet_count\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: CICFlowMeter output CSV not found at {cicflowmeter_output_path}.\")\n",
        "        return None\n",
        "    except ValueError as ve:\n",
        "        print(f\"Configuration Error: {ve}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during merging with CICFlowMeter output: {e}\")\n",
        "        print(traceback.format_exc())\n",
        "        return None"
      ],
      "metadata": {
        "id": "SWFSb51qliVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for attack in attacks:\n",
        "  print('--------------------------------')\n",
        "  print(f\"Processing packet mapping for {attack}\")\n",
        "  print('--------------------------------')\n",
        "  attack_flows = os.listdir(f'/content/{attack}')\n",
        "  for attack_flow in attack_flows:\n",
        "    # do something with attack_flows\n",
        "    file_base_name = attack_flow[:-5]\n",
        "    attack_folder = attack\n",
        "    packet_indices,packet_count = process_pcap_and_map_flows(attack_folder, file_base_name)\n",
        "\n",
        "    if packet_indices is not None:\n",
        "        # start reformat\n",
        "        attack_index_dir = f'/content/{attack}_index'\n",
        "        attack_index_file = f'{file_base_name}_index.csv'\n",
        "        if attack_index_file.endswith('.csv'): # Ensure we're only processing CSV files\n",
        "            file_path = os.path.join(attack_index_dir, attack_index_file)\n",
        "            # print(f\"Processing {file_path}\")\n",
        "\n",
        "            try:\n",
        "                # Read the CSV file\n",
        "                df = pd.read_csv(file_path)\n",
        "\n",
        "                '''\n",
        "                if 'Packet Indices Mapped' in df.columns:\n",
        "                    # Drop all columns except 'Packet Indices Mapping'\n",
        "                    df_reformatted = df[['Packet Indices Mapped']]\n",
        "\n",
        "                    # Save the modified DataFrame back to the same CSV file\n",
        "                    df_reformatted.to_csv(file_path, index=False) # index=False prevents writing DataFrame index as a column\n",
        "                    print(f\"Successfully reformatted {attack_index_file}\")\n",
        "                else:\n",
        "                    print(f\"'{attack_index_file}' does not contain 'Packet Indices Mapped' column. Skipping.\")\n",
        "                '''\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {attack_index_file}: {e}\")\n",
        "    else:\n",
        "      print(f\"packet_indices for {attack_flow} not found skipping...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUI6pH8OR0QI",
        "outputId": "6cb87c0a-e287-4170-a304-823c8d18b594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Processing packet mapping for FTP-Bruteforce\n",
            "--------------------------------\n",
            "\n",
            "--- Starting processing for FTP-Bruteforce/bruteforce_ftp ---\n",
            "PCAP: FTP-Bruteforce/bruteforce_ftp.pcap\n",
            "CICFlowMeter Output: /content/FTP-Bruteforce_csv/bruteforce_ftp_ISCX.csv\n",
            "Merged Output: /content/FTP-Bruteforce_index/bruteforce_ftp_index.csv\n",
            "\n",
            "Starting PCAP processing: FTP-Bruteforce/bruteforce_ftp.pcap\n",
            "\n",
            "PCAP processing complete. Processed 49739 packets.\n",
            "Simulated 3087 flows with more than 1 packet.\n",
            "\n",
            "Loading CICFlowMeter output from: /content/FTP-Bruteforce_csv/bruteforce_ftp_ISCX.csv\n",
            "\n",
            "Merged DataFrame head (showing Flow ID, Packet Count, and Mapped Indices):\n",
            "                                Flow ID Packet Indices Mapped\n",
            "0  192.168.1.70-192.168.1.90-36908-21-6            [161, 164]\n",
            "1  192.168.1.70-192.168.1.90-36922-21-6        [29333, 29334]\n",
            "2  192.168.1.70-192.168.1.90-36914-21-6            [163, 166]\n",
            "3  192.168.1.70-192.168.1.90-36930-21-6            [169, 171]\n",
            "4  192.168.1.70-192.168.1.90-36942-21-6            [170, 172]\n",
            "\n",
            "Updated CICFlowMeter output with packet indices saved to: /content/FTP-Bruteforce_index/bruteforce_ftp_index.csv\n",
            "\n",
            "--- Verification ---\n",
            "Total flows in CICFlowMeter output: 6917\n",
            "Flows successfully mapped to packet indices: 6917\n",
            "Flows in CICFlowMeter output that could NOT be mapped: 0\n",
            "\n",
            "Skipping sample of unmapped flows as 'Packet Count' column was not found.\n",
            "\n",
            "--- Starting processing for FTP-Bruteforce/ftpbrute-ubuntu ---\n",
            "PCAP: FTP-Bruteforce/ftpbrute-ubuntu.pcap\n",
            "CICFlowMeter Output: /content/FTP-Bruteforce_csv/ftpbrute-ubuntu_ISCX.csv\n",
            "Merged Output: /content/FTP-Bruteforce_index/ftpbrute-ubuntu_index.csv\n",
            "\n",
            "Starting PCAP processing: FTP-Bruteforce/ftpbrute-ubuntu.pcap\n",
            "\n",
            "PCAP processing complete. Processed 20340 packets.\n",
            "Simulated 536 flows with more than 1 packet.\n",
            "\n",
            "Loading CICFlowMeter output from: /content/FTP-Bruteforce_csv/ftpbrute-ubuntu_ISCX.csv\n",
            "\n",
            "Merged DataFrame head (showing Flow ID, Packet Count, and Mapped Indices):\n",
            "                                      Flow ID Packet Indices Mapped\n",
            "0  192.168.159.159-192.168.159.160-21-44328-6            [263, 264]\n",
            "1  192.168.159.159-192.168.159.160-21-44328-6            [263, 264]\n",
            "2  192.168.159.159-192.168.159.160-21-44176-6  [278, 291, 315, 316]\n",
            "3  192.168.159.159-192.168.159.160-21-44192-6            [329, 330]\n",
            "4  192.168.159.159-192.168.159.160-21-44190-6            [347, 348]\n",
            "\n",
            "Updated CICFlowMeter output with packet indices saved to: /content/FTP-Bruteforce_index/ftpbrute-ubuntu_index.csv\n",
            "\n",
            "--- Verification ---\n",
            "Total flows in CICFlowMeter output: 1462\n",
            "Flows successfully mapped to packet indices: 1462\n",
            "Flows in CICFlowMeter output that could NOT be mapped: 0\n",
            "\n",
            "Skipping sample of unmapped flows as 'Packet Count' column was not found.\n",
            "\n",
            "--- Starting processing for FTP-Bruteforce/ftpbrute-kali ---\n",
            "PCAP: FTP-Bruteforce/ftpbrute-kali.pcap\n",
            "CICFlowMeter Output: /content/FTP-Bruteforce_csv/ftpbrute-kali_ISCX.csv\n",
            "Merged Output: /content/FTP-Bruteforce_index/ftpbrute-kali_index.csv\n",
            "\n",
            "Starting PCAP processing: FTP-Bruteforce/ftpbrute-kali.pcap\n",
            "\n",
            "PCAP processing complete. Processed 13910 packets.\n",
            "Simulated 416 flows with more than 1 packet.\n",
            "\n",
            "Loading CICFlowMeter output from: /content/FTP-Bruteforce_csv/ftpbrute-kali_ISCX.csv\n",
            "\n",
            "Merged DataFrame head (showing Flow ID, Packet Count, and Mapped Indices):\n",
            "                                      Flow ID Packet Indices Mapped\n",
            "0  192.168.159.159-192.168.159.160-21-60050-6              [22, 23]\n",
            "1  192.168.159.159-192.168.159.160-21-60056-6              [36, 37]\n",
            "2  192.168.159.159-192.168.159.160-21-60066-6              [46, 47]\n",
            "3  192.168.159.159-192.168.159.160-21-60070-6              [55, 56]\n",
            "4  192.168.159.159-192.168.159.160-21-60050-6              [22, 23]\n",
            "\n",
            "Updated CICFlowMeter output with packet indices saved to: /content/FTP-Bruteforce_index/ftpbrute-kali_index.csv\n",
            "\n",
            "--- Verification ---\n",
            "Total flows in CICFlowMeter output: 1217\n",
            "Flows successfully mapped to packet indices: 1217\n",
            "Flows in CICFlowMeter output that could NOT be mapped: 0\n",
            "\n",
            "Skipping sample of unmapped flows as 'Packet Count' column was not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list filename_index.csv to have only indexcolumn\n",
        "for attack in attacks:\n",
        "  print('--------------------------------')\n",
        "  print(f\"Reformat {attack}_index\")\n",
        "  print('--------------------------------')\n",
        "  attack_indexs = os.listdir(f'/content/{attack}_index')\n",
        "  for attack_index in attack_indexs:\n",
        "    print(attack_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6SEVDKSPsBq",
        "outputId": "e907c477-6564-423b-f048-cbc1bf624eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Reformat FTP-Bruteforce_index\n",
            "--------------------------------\n",
            "ftpbrute-kali_index.csv\n",
            ".ipynb_checkpoints\n",
            "bruteforce_ftp_index.csv\n",
            "ftpbrute-ubuntu_index.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predictions"
      ],
      "metadata": {
        "id": "cWj8Jc8PaP1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define function for model loading\n",
        "import joblib\n",
        "def load_model(model_name):\n",
        "  model_path = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/' + model_name\n",
        "  model = joblib.load(model_path)\n",
        "  return model\n",
        "\n",
        "# model = load_model(model_name)\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "_jr1edyCbRu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model_name = 'RandomForest400IntPortCIC1718-2.pkl'\n",
        "model = load_model(model_name)\n",
        "print(model)\n",
        "# attacks = model.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsbzbAwBbZJD",
        "outputId": "3c7b1039-dc5e-4c39-9de0-34d94d8cff45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function for df preprocessing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "def map_port(port):\n",
        "    if port == 21:\n",
        "        return 1  # FTP\n",
        "    elif port == 22:\n",
        "        return 2  # SSH\n",
        "    elif port == 53:\n",
        "        return 3  # DNS\n",
        "    elif port == 80:\n",
        "        return 4  # HTTP\n",
        "    elif port == 443:\n",
        "        return 5  # HTTPS\n",
        "    else:\n",
        "        return 6  # Other\n",
        "\n",
        "def preprocess_dataframe(df):\n",
        "    original_indices = set(df.index)\n",
        "\n",
        "    # replace space in columns name with underscore\n",
        "    df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
        "\n",
        "    df[\"Packet_Indices_Mapped\"] = df[\"Packet_Indices_Mapped\"].apply(ast.literal_eval)\n",
        "\n",
        "    # drop objects type columns\n",
        "    columns_to_drop = [\n",
        "        'Flow_ID','Src_IP','Dst_IP','Src_Port','Protocol','Timestamp','Label'\n",
        "    ]\n",
        "\n",
        "    df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "    # remove rows with missing and infinite values\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df = df.dropna()\n",
        "\n",
        "    # map destination port to 1-6 numbers\n",
        "    df['Dst_Port'] = df['Dst_Port'].apply(map_port)\n",
        "\n",
        "    return df\n",
        "\n",
        "# preprocess_dataframe(df)"
      ],
      "metadata": {
        "id": "IDwhUhlsbpT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for attack in attacks:\n",
        "  print('--------------------------------')\n",
        "  print(f\"Processing {attack}\")\n",
        "  print('--------------------------------')\n",
        "  attack_csv_folder = f'/content/{attack}'\n",
        "  attack_flows = os.listdir(attack_csv_folder)\n",
        "  attack_files = [attack_flow[:-5] for attack_flow in attack_flows]\n",
        "  for attack_file in attack_files:\n",
        "    attack_flow = f'{attack_file}_ISCX.csv'\n",
        "    attack_index = f'{attack_file}_index.csv'\n",
        "    flow_dir= f'/content/{attack}_csv'\n",
        "    index_dir = f'/content/{attack}_index'\n",
        "    # print(f\"{attack_file} , {attack_flow} , {attack_index}\")\n",
        "    # do something with these attack file\n",
        "\n",
        "    df = pd.read_csv(f'{index_dir}/{attack_index}')\n",
        "    df = preprocess_dataframe(df)\n",
        "\n",
        "    df = df[df['Packet_Indices_Mapped'].notna()]  # Remove NaNs\n",
        "    df = df[df['Packet_Indices_Mapped'].astype(str).str.strip() != \"[]\"]\n",
        "\n",
        "    prediction = model.predict(df.drop('Packet_Indices_Mapped', axis=1))\n",
        "    prediction_df = pd.DataFrame(prediction, columns=['Prediction'])\n",
        "\n",
        "    prediction_df['Packet_Indices_Mapped'] = df['Packet_Indices_Mapped'].values\n",
        "    print(prediction_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydsy39O5aHcK",
        "outputId": "711f5d46-518a-4ff8-d396-ccde97b0e9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Processing FTP-Bruteforce\n",
            "--------------------------------\n",
            "     Prediction Packet_Indices_Mapped\n",
            "0        Benign            [161, 164]\n",
            "1        Benign        [29333, 29334]\n",
            "2        Benign            [163, 166]\n",
            "3        Benign            [169, 171]\n",
            "4        Benign            [170, 172]\n",
            "...         ...                   ...\n",
            "6912     Benign        [30005, 30006]\n",
            "6913     Benign        [40102, 40103]\n",
            "6914     Benign        [29349, 29352]\n",
            "6915     Benign        [20999, 21000]\n",
            "6916     Benign        [44922, 44928]\n",
            "\n",
            "[6917 rows x 2 columns]\n",
            "     Prediction Packet_Indices_Mapped\n",
            "0        Benign            [263, 264]\n",
            "1        Benign            [263, 264]\n",
            "2        Benign  [278, 291, 315, 316]\n",
            "3        Benign            [329, 330]\n",
            "4        Benign            [347, 348]\n",
            "...         ...                   ...\n",
            "1436     Benign        [19098, 19099]\n",
            "1437     Benign        [20300, 20301]\n",
            "1438     Benign          [6042, 6043]\n",
            "1439     Benign            [874, 875]\n",
            "1440     Benign        [15612, 15613]\n",
            "\n",
            "[1441 rows x 2 columns]\n",
            "     Prediction Packet_Indices_Mapped\n",
            "0        Benign              [22, 23]\n",
            "1        Benign              [36, 37]\n",
            "2        Benign              [46, 47]\n",
            "3        Benign              [22, 23]\n",
            "4        Benign              [75, 76]\n",
            "...         ...                   ...\n",
            "1020     Benign              [55, 56]\n",
            "1021     Benign        [12684, 12685]\n",
            "1022     Benign        [13885, 13886]\n",
            "1023     Benign          [8034, 8035]\n",
            "1024     Benign          [9197, 9198]\n",
            "\n",
            "[1025 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast # Import ast for literal_eval\n",
        "\n",
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Iterate through each row of the predictions_df\n",
        "for index, row in prediction_df.iterrows():\n",
        "    label = row['Prediction']\n",
        "    packet_indices_list = row['Packet_Indices_Mapped']\n",
        "\n",
        "    # Ensure packet_indices_list is treated as a list\n",
        "    if isinstance(packet_indices_list, str):\n",
        "        try:\n",
        "            packet_indices_list = ast.literal_eval(packet_indices_list)\n",
        "        except (ValueError, SyntaxError):\n",
        "            packet_indices_list = []\n",
        "    elif not isinstance(packet_indices_list, list):\n",
        "         packet_indices_list = []\n",
        "\n",
        "    # Create a list of dictionaries for this flow's packets\n",
        "    if packet_indices_list:\n",
        "        for packet_index in packet_indices_list:\n",
        "            results.append({'Packet_Index': packet_index, 'Label': label})\n",
        "\n",
        "# Create the DataFrame from the results list\n",
        "classified_packets_df = pd.DataFrame(results)\n",
        "\n",
        "# --- Remove duplicate packet indices ---\n",
        "# Sort by Packet_Index to keep the first occurrence if duplicates exist\n",
        "classified_packets_df = classified_packets_df.sort_values(by='Packet_Index').drop_duplicates(subset=['Packet_Index'], keep='first')\n",
        "# --- End of modification ---\n",
        "\n",
        "\n",
        "# Create a DataFrame with all packet indices from 1 to packet_count\n",
        "all_packets_df = pd.DataFrame({'Packet_Index': range(1, packet_count + 1)})\n",
        "\n",
        "# Merge the two DataFrames, keeping all packets from all_packets_df\n",
        "merged_df = pd.merge(all_packets_df, classified_packets_df, on='Packet_Index', how='left')\n",
        "\n",
        "# Fill the NaN values in 'Label' (which represent unclassified packets) with 'Benign'\n",
        "merged_df['Label'] = merged_df['Label'].fillna('-')\n",
        "\n",
        "# Sort by Packet Index for better readability (already sorted by merge, but good practice)\n",
        "packet_label_df = merged_df.sort_values(by='Packet_Index').reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nDataFrame with packet index and predicted label (Total packets: {len(packet_label_df)}):\")\n",
        "# packet_label_df\n",
        "print(packet_label_df[(packet_label_df['Label'] == 'FTP-Bruteforce')])\n",
        "print(packet_label_df['Label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKwpV3nkssyc",
        "outputId": "fb141774-8732-4a83-95b5-ab8c5194d26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with packet index and predicted label (Total packets: 13910):\n",
            "       Packet_Index           Label\n",
            "576             577  FTP-Bruteforce\n",
            "597             598  FTP-Bruteforce\n",
            "607             608  FTP-Bruteforce\n",
            "646             647  FTP-Bruteforce\n",
            "647             648  FTP-Bruteforce\n",
            "...             ...             ...\n",
            "13860         13861  FTP-Bruteforce\n",
            "13861         13862  FTP-Bruteforce\n",
            "13875         13876  FTP-Bruteforce\n",
            "13880         13881  FTP-Bruteforce\n",
            "13888         13889  FTP-Bruteforce\n",
            "\n",
            "[417 rows x 2 columns]\n",
            "Label\n",
            "-                 12968\n",
            "Benign              525\n",
            "FTP-Bruteforce      417\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# archive for map"
      ],
      "metadata": {
        "id": "TQXF-l4UUkLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reformat filename_index.csv to have only indexcolumn\n",
        "import os\n",
        "\n",
        "for attack in attacks:\n",
        "  print('--------------------------------')\n",
        "  print(f\"Reformat {attack}_index\")\n",
        "  print('--------------------------------')\n",
        "  attack_index_files = os.listdir(f'/content/{attack}_index')\n",
        "  for attack_index_file in attack_index_files:\n",
        "    attack_index_dir = f'/content/{attack}_index'\n",
        "    if attack_index_file.endswith('.csv'): # Ensure we're only processing CSV files\n",
        "        file_path = os.path.join(attack_index_dir, attack_index_file)\n",
        "        # print(f\"Processing {file_path}\")\n",
        "\n",
        "        try:\n",
        "            # Read the CSV file\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            if 'Packet Indices Mapped' in df.columns:\n",
        "                # Drop all columns except 'Packet Indices Mapping'\n",
        "                df_reformatted = df[['Packet Indices Mapped']]\n",
        "\n",
        "                # Save the modified DataFrame back to the same CSV file\n",
        "                df_reformatted.to_csv(file_path, index=False) # index=False prevents writing DataFrame index as a column\n",
        "                print(f\"Successfully reformatted {attack_index_file}\")\n",
        "            else:\n",
        "                print(f\"'{attack_index_file}' does not contain 'Packet Indices Mapped' column. Skipping.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {attack_index_file}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-s8KyRJQDQy",
        "outputId": "d49669e2-cf2f-42b1-be02-a2aa5cf529df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Reformat DoS_index\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Reformat DDoS_index\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Reformat PortScan_index\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Reformat Benign_index\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Reformat DoS-HTTP-Flood_index\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Reformat DoS-SlowRate_index\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Reformat Benign2_index\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Reformat DoS-overall_index\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Reformat DoS-Layer3and4_index\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Reformat FTP-Bruteforce_index\n",
            "--------------------------------\n",
            "Successfully reformatted ftpbrute-ubuntu_index.csv\n",
            "--------------------------------\n",
            "Reformat SSH-Bruteforce_index\n",
            "--------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJiGV8LzPx82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cicflowsetup again"
      ],
      "metadata": {
        "id": "TLm6-7pXFFmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libpcap-dev > /content/log.txt # install libpcap-dev\n",
        "!wget https://codeberg.org/iortega/TCPDUMP_and_CICFlowMeter/archive/master:CICFlowMeters/CICFlowMeter-3.0.zip # download CICFlowMeter3.0.zip\n",
        "!unzip CICFlowMeter-3.0.zip -d CICFlowMeter-3.0 # Extract CICFlowMeter3.0.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6JwPqv5yp42y",
        "outputId": "872df66e-d2aa-496f-ac4b-484a70133c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "--2025-06-08 05:24:15--  https://codeberg.org/iortega/TCPDUMP_and_CICFlowMeter/archive/master:CICFlowMeters/CICFlowMeter-3.0.zip\n",
            "Resolving codeberg.org (codeberg.org)... 217.197.84.140, 2a0a:4580:103f:c0de::1\n",
            "Connecting to codeberg.org (codeberg.org)|217.197.84.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15039922 (14M) [application/octet-stream]\n",
            "Saving to: CICFlowMeter-3.0.zip\n",
            "\n",
            "CICFlowMeter-3.0.zi 100%[===================>]  14.34M  11.4MB/s    in 1.3s    \n",
            "\n",
            "2025-06-08 05:24:17 (11.4 MB/s) - CICFlowMeter-3.0.zip saved [15039922/15039922]\n",
            "\n",
            "Archive:  CICFlowMeter-3.0.zip\n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/LICENSE.txt  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/README.md  \n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter.bat  \n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/CICFlowMeter-3.0.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/animal-sniffer-annotations-1.14.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/checker-compat-qual-2.0.0.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/commons-io-2.5.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/commons-lang3-3.6.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/commons-math3-3.5.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/error_prone_annotations-2.1.3.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/guava-23.6-jre.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/hamcrest-core-1.3.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/j2objc-annotations-1.1.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/java-cup-0.11a.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/jfreechart-1.5.0.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/jnetpcap-1.4.r1425-1g.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/jsr305-1.3.9.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/junit-4.12.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/log4j-1.2.17.jar  \n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/jnetpcap-pcap100.dll  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/jnetpcap.dll  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/libjnetpcap-pcap100.so  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/libjnetpcap.so  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/slf4j-api-1.7.25.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/slf4j-log4j12-1.7.25.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/tika-core-1.17.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/weka-stable-3.6.14.jar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x ./CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter"
      ],
      "metadata": {
        "id": "SwFZ2rsV7QIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory paths\n",
        "in_directory = 'data/in'\n",
        "out_directory = 'data/out'\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "os.makedirs(in_directory, exist_ok=True)\n",
        "os.makedirs(out_directory, exist_ok=True)\n",
        "\n",
        "print(f\"Directories '{in_directory}' and '{out_directory}' created (if they didn't exist).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVG5iRFVO5AI",
        "outputId": "7919aadf-230c-4a9d-d0f4-3882c4b2c21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories 'data/in' and 'data/out' created (if they didn't exist).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert each attack to iscx"
      ],
      "metadata": {
        "id": "srI7OsUjFAoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "attacks = ['FTP-Bruteforce']\n",
        "\n",
        "for attack in attacks:\n",
        "  print('--------------------------------')\n",
        "  print(f\"Processing : {attack}\")\n",
        "  print('--------------------------------')\n",
        "  attack_folder = f'/content/{attack}'\n",
        "  attack_pcaps = os.listdir(attack_folder)\n",
        "  for attack_pcap in attack_pcaps:\n",
        "    # do something with each attack pcap\n",
        "    print(f\"Processing : {attack_pcap}\")\n",
        "    # convert file.pcap to flow\n",
        "    # move pcap file to data/out\n",
        "    data_in_folder = '/content/data/in'\n",
        "    try:\n",
        "      shutil.move(f'{attack_folder}/{attack_pcap}',data_in_folder)\n",
        "      # run cicflowmeter\n",
        "      cicflowmeter_command = './CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter'\n",
        "      subprocess.run([cicflowmeter_command], check=True, capture_output=True, text=True)\n",
        "      print(f\"Converted {attack_pcap} to flow\")\n",
        "      # create attack_flow folder\n",
        "      flow_destination_directory = f'{attack}_flow'\n",
        "      os.makedirs(flow_destination_directory, exist_ok=True)\n",
        "      print(f\"Directory '{flow_destination_directory}' created (if it didn't exist).\")\n",
        "      # move attack pcap from data/in back to attack_folder\n",
        "      shutil.move(f'{data_in_folder}/{attack_pcap}',attack_folder)\n",
        "      # move file_ISCX.csv to attack_flow folder\n",
        "      data_out_folder = '/content/data/out'\n",
        "      flow_file_name = attack_pcap[:-5] + '_ISCX.csv'\n",
        "      shutil.move(f'{data_out_folder}/{flow_file_name}',flow_destination_directory)\n",
        "      print(f\"Moved {flow_file_name} to {flow_destination_directory}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ3iiEFEqHsd",
        "outputId": "a8ed4912-d6b8-499f-e699-5a2155a72c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Processing : FTP-Bruteforce\n",
            "--------------------------------\n",
            "Processing : bruteforce_ftp.pcap\n",
            "Converted bruteforce_ftp.pcap to flow\n",
            "Directory 'FTP-Bruteforce_flow' created (if it didn't exist).\n",
            "Moved bruteforce_ftp_ISCX.csv to FTP-Bruteforce_flow\n",
            "Processing : ftpbrute-ubuntu.pcap\n",
            "Converted ftpbrute-ubuntu.pcap to flow\n",
            "Directory 'FTP-Bruteforce_flow' created (if it didn't exist).\n",
            "Moved ftpbrute-ubuntu_ISCX.csv to FTP-Bruteforce_flow\n",
            "Processing : ftpbrute-kali.pcap\n",
            "Converted ftpbrute-kali.pcap to flow\n",
            "Directory 'FTP-Bruteforce_flow' created (if it didn't exist).\n",
            "Moved ftpbrute-kali_ISCX.csv to FTP-Bruteforce_flow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZfyWP8TEAmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# clean"
      ],
      "metadata": {
        "id": "fL2Jdmy58F7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rmdir /content/SSH-Bruteforce --ignore-fail-on-non-empty\n",
        "!rmdir /content/FTP-Bruteforce --ignore-fail-on-non-empty"
      ],
      "metadata": {
        "id": "yrO2hp1M653k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CICFlowMeterSetup"
      ],
      "metadata": {
        "id": "fFyVqFnOkshn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libpcap-dev # install libpcap-dev\n",
        "!wget https://codeberg.org/iortega/TCPDUMP_and_CICFlowMeter/archive/master:CICFlowMeters/CICFlowMeter-3.0.zip # download CICFlowMeter3.0.zip\n",
        "!unzip CICFlowMeter-3.0.zip -d CICFlowMeter-3.0 # Extract CICFlowMeter3.0.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad_Q5HTgOhcR",
        "outputId": "384a2ebe-13e2-4d06-8247-273287abdbd3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libdbus-1-dev libpcap0.8 libpcap0.8-dev\n",
            "The following NEW packages will be installed:\n",
            "  libdbus-1-dev libpcap-dev libpcap0.8 libpcap0.8-dev\n",
            "0 upgraded, 4 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 607 kB of archives.\n",
            "After this operation, 2,238 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcap0.8 amd64 1.10.1-4ubuntu1.22.04.1 [145 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-dev amd64 1.12.20-2ubuntu4.1 [188 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcap0.8-dev amd64 1.10.1-4ubuntu1.22.04.1 [270 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcap-dev amd64 1.10.1-4ubuntu1.22.04.1 [3,326 B]\n",
            "Fetched 607 kB in 1s (485 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpcap0.8:amd64.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../libpcap0.8_1.10.1-4ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libpcap0.8:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Selecting previously unselected package libdbus-1-dev:amd64.\n",
            "Preparing to unpack .../libdbus-1-dev_1.12.20-2ubuntu4.1_amd64.deb ...\n",
            "Unpacking libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Selecting previously unselected package libpcap0.8-dev:amd64.\n",
            "Preparing to unpack .../libpcap0.8-dev_1.10.1-4ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libpcap0.8-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Selecting previously unselected package libpcap-dev:amd64.\n",
            "Preparing to unpack .../libpcap-dev_1.10.1-4ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libpcap-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Setting up libpcap0.8:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Setting up libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Setting up libpcap0.8-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Setting up libpcap-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "--2025-06-05 05:28:32--  https://codeberg.org/iortega/TCPDUMP_and_CICFlowMeter/archive/master:CICFlowMeters/CICFlowMeter-3.0.zip\n",
            "Resolving codeberg.org (codeberg.org)... 217.197.84.140, 2a0a:4580:103f:c0de::1\n",
            "Connecting to codeberg.org (codeberg.org)|217.197.84.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15039922 (14M) [application/octet-stream]\n",
            "Saving to: CICFlowMeter-3.0.zip\n",
            "\n",
            "CICFlowMeter-3.0.zi 100%[===================>]  14.34M  7.46MB/s    in 1.9s    \n",
            "\n",
            "2025-06-05 05:28:35 (7.46 MB/s) - CICFlowMeter-3.0.zip saved [15039922/15039922]\n",
            "\n",
            "Archive:  CICFlowMeter-3.0.zip\n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/LICENSE.txt  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/README.md  \n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/bin/CICFlowMeter.bat  \n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/CICFlowMeter-3.0.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/animal-sniffer-annotations-1.14.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/checker-compat-qual-2.0.0.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/commons-io-2.5.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/commons-lang3-3.6.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/commons-math3-3.5.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/error_prone_annotations-2.1.3.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/guava-23.6-jre.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/hamcrest-core-1.3.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/j2objc-annotations-1.1.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/java-cup-0.11a.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/jfreechart-1.5.0.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/jnetpcap-1.4.r1425-1g.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/jsr305-1.3.9.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/junit-4.12.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/log4j-1.2.17.jar  \n",
            "   creating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/\n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/jnetpcap-pcap100.dll  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/jnetpcap.dll  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/libjnetpcap-pcap100.so  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/native/libjnetpcap.so  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/slf4j-api-1.7.25.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/slf4j-log4j12-1.7.25.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/tika-core-1.17.jar  \n",
            "  inflating: CICFlowMeter-3.0/tcpdump_and_cicflowmeter/lib/weka-stable-3.6.14.jar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory paths\n",
        "in_directory = 'data/in'\n",
        "out_directory = 'data/out'\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "os.makedirs(in_directory, exist_ok=True)\n",
        "os.makedirs(out_directory, exist_ok=True)\n",
        "\n",
        "print(f\"Directories '{in_directory}' and '{out_directory}' created (if they didn't exist).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwqH6JRmOspe",
        "outputId": "fe6205c4-c458-46d4-e28e-eda35a1c8c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories 'data/in' and 'data/out' created (if they didn't exist).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup attack_csv"
      ],
      "metadata": {
        "id": "iyfKM07nOPDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def list_csv_files(attack):\n",
        "\n",
        "  # list attack_csv.zip file\n",
        "  attack = attack + '_csv'\n",
        "  directory_path = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv'\n",
        "\n",
        "  if os.path.exists(directory_path):\n",
        "    contents = os.listdir(directory_path)\n",
        "    for item in contents:\n",
        "      print(item)\n",
        "  else:\n",
        "    print(f\"Directory not found: {directory_path}\")\n",
        "\n",
        "\n",
        "  print(\"\\n-------------------------\\n\")\n",
        "  # unzip attack_csv.zip file\n",
        "  zip_file_path = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv/' + attack + '.zip'\n",
        "  destination_directory = '/content/'\n",
        "\n",
        "  try:\n",
        "      with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "          zip_ref.extractall(destination_directory)\n",
        "      print(f\"'{zip_file_path}' unzipped to '{destination_directory}'.\")\n",
        "  except FileNotFoundError:\n",
        "      print(f\"Error: Zip file not found at '{zip_file_path}'\")\n",
        "  except zipfile.BadZipFile:\n",
        "      print(f\"Error: '{zip_file_path}' is not a valid zip file.\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "  print(\"\\n-------------------------\\n\")\n",
        "  # list unzipped attack_csv files\n",
        "  directory = attack\n",
        "  csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
        "\n",
        "  if csv_files:\n",
        "      print(f\"Found {len(csv_files)} .csv files in '{directory}':\")\n",
        "      for csv_file in csv_files:\n",
        "          print(csv_file)\n",
        "  else:\n",
        "      print(f\"No .csv files found in '{directory}'.\")\n",
        "\n",
        "# list_csv_files(attack)"
      ],
      "metadata": {
        "id": "-les9jqek6FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "EZ_mNHJ7mHrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "def load_model(model_name):\n",
        "  model_path = '/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/' + model_name\n",
        "  model = joblib.load(model_path)\n",
        "  return model\n",
        "\n",
        "# model = load_model(model_name)\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "RP9-owkCSRnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concat and Label same type csv and load as dataframe"
      ],
      "metadata": {
        "id": "ZE5Hn1tQntgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def concat_csv(attack):\n",
        "  # list unzipped attack_csv files\n",
        "  attack_folder = attack + '_csv'\n",
        "  directory = attack_folder\n",
        "  csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
        "\n",
        "  all_csv_data = []\n",
        "\n",
        "  # add attack to label and concat csvs\n",
        "  if csv_files:\n",
        "      print(f\"Found {len(csv_files)} .csv files in '{directory}':\")\n",
        "      for csv_file in csv_files:\n",
        "          print(csv_file)\n",
        "          file_path = os.path.join(directory, csv_file)\n",
        "          try:\n",
        "              df = pd.read_csv(file_path)\n",
        "              df['Label'] = attack\n",
        "              all_csv_data.append(df)\n",
        "          except Exception as e:\n",
        "              print(f\"Error reading {csv_file}: {e}\")\n",
        "\n",
        "      print(\"\\n-------------------------\\n\")\n",
        "      if all_csv_data:\n",
        "          concatenated_df = pd.concat(all_csv_data, ignore_index=True)\n",
        "          print(\"All CSV files concatenated into a single DataFrame.\")\n",
        "          return concatenated_df\n",
        "      else:\n",
        "          print(\"No data read from CSV files.\")\n",
        "          return pd.DataFrame()\n",
        "  else:\n",
        "      print(f\"No .csv files found in '{directory}'.\")\n",
        "      return pd.DataFrame()"
      ],
      "metadata": {
        "id": "XE6xRLdAnx7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre process dataframe"
      ],
      "metadata": {
        "id": "aKPqgcBYThy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def map_port(port):\n",
        "    if port == 21:\n",
        "        return 1  # FTP\n",
        "    elif port == 22:\n",
        "        return 2  # SSH\n",
        "    elif port == 53:\n",
        "        return 3  # DNS\n",
        "    elif port == 80:\n",
        "        return 4  # HTTP\n",
        "    elif port == 443:\n",
        "        return 5  # HTTPS\n",
        "    else:\n",
        "        return 6  # Other\n",
        "\n",
        "def preprocess_dataframe(df):\n",
        "    # replace space in columns name with underscore\n",
        "    df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
        "\n",
        "    # drop objects type columns\n",
        "    columns_to_drop = [\n",
        "        'Flow_ID','Src_IP','Dst_IP','Src_Port','Protocol','Timestamp'\n",
        "    ]\n",
        "\n",
        "    df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "    # remove rows with missing and infinite values\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
        "    df = df.dropna()\n",
        "\n",
        "    # map destination port to 1-6 numbers\n",
        "    df['Dst_Port'] = df['Dst_Port'].apply(map_port)\n",
        "\n",
        "    return df\n",
        "\n",
        "# preprocess_dataframe(df)"
      ],
      "metadata": {
        "id": "-gjAMMZVo2vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Prediction"
      ],
      "metadata": {
        "id": "18RZ1HMbugQi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edc9b0b9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd # Import pandas to display confusion matrix nicely\n",
        "from IPython.display import display # Import display\n",
        "\n",
        "def make_prediction(model, df):\n",
        "  # Split the dataframe into features (X) and labels (y)\n",
        "  X = df.drop('Label', axis=1)\n",
        "  y = df['Label']\n",
        "\n",
        "  # Make predictions\n",
        "  predictions = model.predict(X)\n",
        "\n",
        "  # Calculate and print the classification report\n",
        "  print(classification_report(y, predictions))\n",
        "\n",
        "  # Calculate and print the confusion matrix\n",
        "  cm = confusion_matrix(y, predictions, labels=model.classes_)\n",
        "  cm_df = pd.DataFrame(cm, index=model.classes_, columns=model.classes_)\n",
        "  print(\"\\nConfusion Matrix:\")\n",
        "  display(cm_df) # Use display() instead of print()\n",
        "\n",
        "# make_prediction(model, df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "VisBSN1_TlPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attack = 'SSH-Bruteforce'\n",
        "model_name = 'RandomForest400IntPortCIC1718-2.pkl'\n",
        "\n",
        "model = load_model(model_name)\n",
        "attacks = model.classes_\n",
        "\n",
        "for attack in attacks:\n",
        "  list_csv_files(attack)\n",
        "  df = concat_csv(attack)\n",
        "  df = preprocess_dataframe(df)\n",
        "  print(f\"Prediction of {attack}\")\n",
        "  make_prediction(model, df)"
      ],
      "metadata": {
        "id": "4nC6L9LxqSFd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "5eae24f2-e6ab-4680-8e08-9b11de3376e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS_csv.zip\n",
            "DDoS_csv.zip\n",
            "PortScan_csv.zip\n",
            "Benign_csv.zip\n",
            "DoS-HTTP-Flood_csv.zip\n",
            "DoS-Layer3and4_csv.zip\n",
            "DoS-overall_csv.zip\n",
            "FTP-Bruteforce_csv.zip\n",
            "SSH-Bruteforce_csv.zip\n",
            "DoS-Slow-Rate_csv.zip\n",
            "\n",
            "-------------------------\n",
            "\n",
            "'/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv/Benign_csv.zip' unzipped to '/content/'.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Found 21 .csv files in 'Benign_csv':\n",
            "normal_10_ISCX.csv\n",
            "Normal-h3_11_ISCX.csv\n",
            "DoS-Hulk_benign_ISCX.csv\n",
            "Normal-h3_6_ISCX.csv\n",
            "normal_12_ISCX.csv\n",
            "Normal-h3_2_ISCX.csv\n",
            "Normal-h3_10_ISCX.csv\n",
            "normal_3_ISCX.csv\n",
            "normal_2_ISCX.csv\n",
            "Normal-h3_1_ISCX.csv\n",
            "Normal-h3_5_ISCX.csv\n",
            "normal_11_ISCX.csv\n",
            "Normal-h3_4_ISCX.csv\n",
            "Normal-h3_3_ISCX.csv\n",
            "Normal-h3_8_ISCX.csv\n",
            "normal_4_ISCX.csv\n",
            "normal_13_ISCX.csv\n",
            "Normal-h3_12_ISCX.csv\n",
            "Normal-h3_9_ISCX.csv\n",
            "DoS-GoldenEye_benign_ISCX.csv\n",
            "normal_1_ISCX.csv\n",
            "Found 21 .csv files in 'Benign_csv':\n",
            "normal_10_ISCX.csv\n",
            "Normal-h3_11_ISCX.csv\n",
            "DoS-Hulk_benign_ISCX.csv\n",
            "Normal-h3_6_ISCX.csv\n",
            "normal_12_ISCX.csv\n",
            "Normal-h3_2_ISCX.csv\n",
            "Normal-h3_10_ISCX.csv\n",
            "normal_3_ISCX.csv\n",
            "normal_2_ISCX.csv\n",
            "Normal-h3_1_ISCX.csv\n",
            "Normal-h3_5_ISCX.csv\n",
            "normal_11_ISCX.csv\n",
            "Normal-h3_4_ISCX.csv\n",
            "Normal-h3_3_ISCX.csv\n",
            "Normal-h3_8_ISCX.csv\n",
            "normal_4_ISCX.csv\n",
            "normal_13_ISCX.csv\n",
            "Normal-h3_12_ISCX.csv\n",
            "Normal-h3_9_ISCX.csv\n",
            "DoS-GoldenEye_benign_ISCX.csv\n",
            "normal_1_ISCX.csv\n",
            "\n",
            "-------------------------\n",
            "\n",
            "All CSV files concatenated into a single DataFrame.\n",
            "Prediction of Benign\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "        Benign       1.00      1.00      1.00     58686\n",
            " DoS-Slow-Rate       0.00      0.00      0.00         0\n",
            "SSH-Bruteforce       0.00      0.00      0.00         0\n",
            "\n",
            "      accuracy                           1.00     58686\n",
            "     macro avg       0.33      0.33      0.33     58686\n",
            "  weighted avg       1.00      1.00      1.00     58686\n",
            "\n",
            "\n",
            "Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Benign  DoS-HTTP-Flood  DoS-Slow-Rate  FTP-Bruteforce  \\\n",
              "Benign           58684               0              1               0   \n",
              "DoS-HTTP-Flood       0               0              0               0   \n",
              "DoS-Slow-Rate        0               0              0               0   \n",
              "FTP-Bruteforce       0               0              0               0   \n",
              "PortScan             0               0              0               0   \n",
              "SSH-Bruteforce       0               0              0               0   \n",
              "\n",
              "                PortScan  SSH-Bruteforce  \n",
              "Benign                 0               1  \n",
              "DoS-HTTP-Flood         0               0  \n",
              "DoS-Slow-Rate          0               0  \n",
              "FTP-Bruteforce         0               0  \n",
              "PortScan               0               0  \n",
              "SSH-Bruteforce         0               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eed7d438-2539-4759-ac57-24bfc1f08c3d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Benign</th>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <th>PortScan</th>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>58684</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PortScan</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eed7d438-2539-4759-ac57-24bfc1f08c3d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eed7d438-2539-4759-ac57-24bfc1f08c3d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eed7d438-2539-4759-ac57-24bfc1f08c3d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0cf65c9c-60e0-458e-a368-ce345f00b667\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0cf65c9c-60e0-458e-a368-ce345f00b667')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0cf65c9c-60e0-458e-a368-ce345f00b667 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  make_prediction(model, df)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Benign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23957,\n        \"min\": 0,\n        \"max\": 58684,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          58684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-HTTP-Flood\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-Slow-Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FTP-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PortScan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SSH-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS_csv.zip\n",
            "DDoS_csv.zip\n",
            "PortScan_csv.zip\n",
            "Benign_csv.zip\n",
            "DoS-HTTP-Flood_csv.zip\n",
            "DoS-Layer3and4_csv.zip\n",
            "DoS-overall_csv.zip\n",
            "FTP-Bruteforce_csv.zip\n",
            "SSH-Bruteforce_csv.zip\n",
            "DoS-Slow-Rate_csv.zip\n",
            "\n",
            "-------------------------\n",
            "\n",
            "'/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv/DoS-HTTP-Flood_csv.zip' unzipped to '/content/'.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Found 6 .csv files in 'DoS-HTTP-Flood_csv':\n",
            "DoS-Hulk_attack_ISCX.csv\n",
            "DoS-GoldenEye_attack_ISCX.csv\n",
            "GoldenEye_ISCX.csv\n",
            "hulk_ISCX.csv\n",
            "DDoS HTTP Flood Attacks_ISCX.csv\n",
            "http_dos_ISCX.csv\n",
            "Found 6 .csv files in 'DoS-HTTP-Flood_csv':\n",
            "DoS-Hulk_attack_ISCX.csv\n",
            "DoS-GoldenEye_attack_ISCX.csv\n",
            "GoldenEye_ISCX.csv\n",
            "hulk_ISCX.csv\n",
            "DDoS HTTP Flood Attacks_ISCX.csv\n",
            "http_dos_ISCX.csv\n",
            "\n",
            "-------------------------\n",
            "\n",
            "All CSV files concatenated into a single DataFrame.\n",
            "Prediction of DoS-HTTP-Flood\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "        Benign       0.00      0.00      0.00         0\n",
            "DoS-HTTP-Flood       1.00      0.04      0.07    194671\n",
            " DoS-Slow-Rate       0.00      0.00      0.00         0\n",
            "\n",
            "      accuracy                           0.04    194671\n",
            "     macro avg       0.33      0.01      0.02    194671\n",
            "  weighted avg       1.00      0.04      0.07    194671\n",
            "\n",
            "\n",
            "Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Benign  DoS-HTTP-Flood  DoS-Slow-Rate  FTP-Bruteforce  \\\n",
              "Benign               0               0              0               0   \n",
              "DoS-HTTP-Flood  179010            7019           8642               0   \n",
              "DoS-Slow-Rate        0               0              0               0   \n",
              "FTP-Bruteforce       0               0              0               0   \n",
              "PortScan             0               0              0               0   \n",
              "SSH-Bruteforce       0               0              0               0   \n",
              "\n",
              "                PortScan  SSH-Bruteforce  \n",
              "Benign                 0               0  \n",
              "DoS-HTTP-Flood         0               0  \n",
              "DoS-Slow-Rate          0               0  \n",
              "FTP-Bruteforce         0               0  \n",
              "PortScan               0               0  \n",
              "SSH-Bruteforce         0               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f65223c-b879-4372-8235-db30c4676a5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Benign</th>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <th>PortScan</th>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <td>179010</td>\n",
              "      <td>7019</td>\n",
              "      <td>8642</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PortScan</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f65223c-b879-4372-8235-db30c4676a5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f65223c-b879-4372-8235-db30c4676a5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f65223c-b879-4372-8235-db30c4676a5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e09416b-83fe-47f3-b76e-395ae42293c0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e09416b-83fe-47f3-b76e-395ae42293c0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e09416b-83fe-47f3-b76e-395ae42293c0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  make_prediction(model, df)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Benign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73080,\n        \"min\": 0,\n        \"max\": 179010,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          179010,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-HTTP-Flood\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2865,\n        \"min\": 0,\n        \"max\": 7019,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7019,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-Slow-Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3528,\n        \"min\": 0,\n        \"max\": 8642,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8642,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FTP-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PortScan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SSH-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS_csv.zip\n",
            "DDoS_csv.zip\n",
            "PortScan_csv.zip\n",
            "Benign_csv.zip\n",
            "DoS-HTTP-Flood_csv.zip\n",
            "DoS-Layer3and4_csv.zip\n",
            "DoS-overall_csv.zip\n",
            "FTP-Bruteforce_csv.zip\n",
            "SSH-Bruteforce_csv.zip\n",
            "DoS-Slow-Rate_csv.zip\n",
            "\n",
            "-------------------------\n",
            "\n",
            "'/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv/DoS-Slow-Rate_csv.zip' unzipped to '/content/'.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Found 4 .csv files in 'DoS-Slow-Rate_csv':\n",
            "slowread_1_ISCX.csv\n",
            "slowread_2_ISCX.csv\n",
            "lowrateddosMQTT_ISCX.csv\n",
            "http_slowloris_ISCX.csv\n",
            "Found 4 .csv files in 'DoS-Slow-Rate_csv':\n",
            "slowread_1_ISCX.csv\n",
            "slowread_2_ISCX.csv\n",
            "lowrateddosMQTT_ISCX.csv\n",
            "http_slowloris_ISCX.csv\n",
            "\n",
            "-------------------------\n",
            "\n",
            "All CSV files concatenated into a single DataFrame.\n",
            "Prediction of DoS-Slow-Rate\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Benign       0.00      0.00      0.00         0\n",
            "DoS-Slow-Rate       1.00      0.02      0.04     51652\n",
            "\n",
            "     accuracy                           0.02     51652\n",
            "    macro avg       0.50      0.01      0.02     51652\n",
            " weighted avg       1.00      0.02      0.04     51652\n",
            "\n",
            "\n",
            "Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Benign  DoS-HTTP-Flood  DoS-Slow-Rate  FTP-Bruteforce  \\\n",
              "Benign               0               0              0               0   \n",
              "DoS-HTTP-Flood       0               0              0               0   \n",
              "DoS-Slow-Rate    50652               0           1000               0   \n",
              "FTP-Bruteforce       0               0              0               0   \n",
              "PortScan             0               0              0               0   \n",
              "SSH-Bruteforce       0               0              0               0   \n",
              "\n",
              "                PortScan  SSH-Bruteforce  \n",
              "Benign                 0               0  \n",
              "DoS-HTTP-Flood         0               0  \n",
              "DoS-Slow-Rate          0               0  \n",
              "FTP-Bruteforce         0               0  \n",
              "PortScan               0               0  \n",
              "SSH-Bruteforce         0               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9c64943-308f-4625-a272-f1fc86680065\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Benign</th>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <th>PortScan</th>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <td>50652</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PortScan</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9c64943-308f-4625-a272-f1fc86680065')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9c64943-308f-4625-a272-f1fc86680065 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9c64943-308f-4625-a272-f1fc86680065');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c0841e4c-a070-4d32-a53a-6d45fa0428a0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0841e4c-a070-4d32-a53a-6d45fa0428a0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c0841e4c-a070-4d32-a53a-6d45fa0428a0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  make_prediction(model, df)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Benign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20678,\n        \"min\": 0,\n        \"max\": 50652,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50652,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-HTTP-Flood\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-Slow-Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 408,\n        \"min\": 0,\n        \"max\": 1000,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FTP-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PortScan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SSH-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS_csv.zip\n",
            "DDoS_csv.zip\n",
            "PortScan_csv.zip\n",
            "Benign_csv.zip\n",
            "DoS-HTTP-Flood_csv.zip\n",
            "DoS-Layer3and4_csv.zip\n",
            "DoS-overall_csv.zip\n",
            "FTP-Bruteforce_csv.zip\n",
            "SSH-Bruteforce_csv.zip\n",
            "DoS-Slow-Rate_csv.zip\n",
            "\n",
            "-------------------------\n",
            "\n",
            "'/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv/FTP-Bruteforce_csv.zip' unzipped to '/content/'.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Found 3 .csv files in 'FTP-Bruteforce_csv':\n",
            "ftpbrute-kali_ISCX.csv\n",
            "ftpbrute-ubuntu_ISCX.csv\n",
            "bruteforce_ftp_ISCX.csv\n",
            "Found 3 .csv files in 'FTP-Bruteforce_csv':\n",
            "ftpbrute-kali_ISCX.csv\n",
            "ftpbrute-ubuntu_ISCX.csv\n",
            "bruteforce_ftp_ISCX.csv\n",
            "\n",
            "-------------------------\n",
            "\n",
            "All CSV files concatenated into a single DataFrame.\n",
            "Prediction of FTP-Bruteforce\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "        Benign       0.00      0.00      0.00         0\n",
            "FTP-Bruteforce       1.00      0.10      0.18      9400\n",
            "\n",
            "      accuracy                           0.10      9400\n",
            "     macro avg       0.50      0.05      0.09      9400\n",
            "  weighted avg       1.00      0.10      0.18      9400\n",
            "\n",
            "\n",
            "Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Benign  DoS-HTTP-Flood  DoS-Slow-Rate  FTP-Bruteforce  \\\n",
              "Benign               0               0              0               0   \n",
              "DoS-HTTP-Flood       0               0              0               0   \n",
              "DoS-Slow-Rate        0               0              0               0   \n",
              "FTP-Bruteforce    8497               0              0             903   \n",
              "PortScan             0               0              0               0   \n",
              "SSH-Bruteforce       0               0              0               0   \n",
              "\n",
              "                PortScan  SSH-Bruteforce  \n",
              "Benign                 0               0  \n",
              "DoS-HTTP-Flood         0               0  \n",
              "DoS-Slow-Rate          0               0  \n",
              "FTP-Bruteforce         0               0  \n",
              "PortScan               0               0  \n",
              "SSH-Bruteforce         0               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e7ff849-bd4e-4a2e-b467-e8336ee5cef5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Benign</th>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <th>PortScan</th>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <td>8497</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>903</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PortScan</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e7ff849-bd4e-4a2e-b467-e8336ee5cef5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e7ff849-bd4e-4a2e-b467-e8336ee5cef5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e7ff849-bd4e-4a2e-b467-e8336ee5cef5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2767ea74-dda3-4826-926f-5bf7290844bb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2767ea74-dda3-4826-926f-5bf7290844bb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2767ea74-dda3-4826-926f-5bf7290844bb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  make_prediction(model, df)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Benign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3468,\n        \"min\": 0,\n        \"max\": 8497,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8497,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-HTTP-Flood\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-Slow-Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FTP-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 368,\n        \"min\": 0,\n        \"max\": 903,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          903\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PortScan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SSH-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS_csv.zip\n",
            "DDoS_csv.zip\n",
            "PortScan_csv.zip\n",
            "Benign_csv.zip\n",
            "DoS-HTTP-Flood_csv.zip\n",
            "DoS-Layer3and4_csv.zip\n",
            "DoS-overall_csv.zip\n",
            "FTP-Bruteforce_csv.zip\n",
            "SSH-Bruteforce_csv.zip\n",
            "DoS-Slow-Rate_csv.zip\n",
            "\n",
            "-------------------------\n",
            "\n",
            "'/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv/PortScan_csv.zip' unzipped to '/content/'.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Found 10 .csv files in 'PortScan_csv':\n",
            "nmap_fin_ISCX.csv\n",
            "normal_scanning4_ISCX.csv\n",
            "normal_scanning6_ISCX.csv\n",
            "normal_scanning3_ISCX.csv\n",
            "nmap_null_ISCX.csv\n",
            "normal_scanning1_ISCX.csv\n",
            "portscan_ISCX.csv\n",
            "Port Scanning attack_ISCX.csv\n",
            "normal_scanning5_ISCX.csv\n",
            "normal_scanning2_ISCX.csv\n",
            "Found 10 .csv files in 'PortScan_csv':\n",
            "nmap_fin_ISCX.csv\n",
            "normal_scanning4_ISCX.csv\n",
            "normal_scanning6_ISCX.csv\n",
            "normal_scanning3_ISCX.csv\n",
            "nmap_null_ISCX.csv\n",
            "normal_scanning1_ISCX.csv\n",
            "portscan_ISCX.csv\n",
            "Port Scanning attack_ISCX.csv\n",
            "normal_scanning5_ISCX.csv\n",
            "normal_scanning2_ISCX.csv\n",
            "\n",
            "-------------------------\n",
            "\n",
            "All CSV files concatenated into a single DataFrame.\n",
            "Prediction of PortScan\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.00      0.00      0.00       0.0\n",
            "    PortScan       0.00      0.00      0.00  146127.0\n",
            "\n",
            "    accuracy                           0.00  146127.0\n",
            "   macro avg       0.00      0.00      0.00  146127.0\n",
            "weighted avg       0.00      0.00      0.00  146127.0\n",
            "\n",
            "\n",
            "Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Benign  DoS-HTTP-Flood  DoS-Slow-Rate  FTP-Bruteforce  \\\n",
              "Benign               0               0              0               0   \n",
              "DoS-HTTP-Flood       0               0              0               0   \n",
              "DoS-Slow-Rate        0               0              0               0   \n",
              "FTP-Bruteforce       0               0              0               0   \n",
              "PortScan        146127               0              0               0   \n",
              "SSH-Bruteforce       0               0              0               0   \n",
              "\n",
              "                PortScan  SSH-Bruteforce  \n",
              "Benign                 0               0  \n",
              "DoS-HTTP-Flood         0               0  \n",
              "DoS-Slow-Rate          0               0  \n",
              "FTP-Bruteforce         0               0  \n",
              "PortScan               0               0  \n",
              "SSH-Bruteforce         0               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc28fae2-9cce-4ba9-b798-0b1f13018c31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Benign</th>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <th>PortScan</th>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PortScan</th>\n",
              "      <td>146127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc28fae2-9cce-4ba9-b798-0b1f13018c31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc28fae2-9cce-4ba9-b798-0b1f13018c31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc28fae2-9cce-4ba9-b798-0b1f13018c31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d913e297-8d54-4767-b804-e01161c2e32b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d913e297-8d54-4767-b804-e01161c2e32b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d913e297-8d54-4767-b804-e01161c2e32b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  make_prediction(model, df)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Benign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59656,\n        \"min\": 0,\n        \"max\": 146127,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          146127,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-HTTP-Flood\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-Slow-Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FTP-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PortScan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SSH-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoS_csv.zip\n",
            "DDoS_csv.zip\n",
            "PortScan_csv.zip\n",
            "Benign_csv.zip\n",
            "DoS-HTTP-Flood_csv.zip\n",
            "DoS-Layer3and4_csv.zip\n",
            "DoS-overall_csv.zip\n",
            "FTP-Bruteforce_csv.zip\n",
            "SSH-Bruteforce_csv.zip\n",
            "DoS-Slow-Rate_csv.zip\n",
            "\n",
            "-------------------------\n",
            "\n",
            "'/content/drive/MyDrive/Share to Mc4/AIBuilders5-MiN/TestsetForbaseline_csv/SSH-Bruteforce_csv.zip' unzipped to '/content/'.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Found 3 .csv files in 'SSH-Bruteforce_csv':\n",
            "bruteforce_ssh_ISCX.csv\n",
            "sshbrute-kali_ISCX.csv\n",
            "sshbrute-ubuntu_ISCX.csv\n",
            "Found 3 .csv files in 'SSH-Bruteforce_csv':\n",
            "bruteforce_ssh_ISCX.csv\n",
            "sshbrute-kali_ISCX.csv\n",
            "sshbrute-ubuntu_ISCX.csv\n",
            "\n",
            "-------------------------\n",
            "\n",
            "All CSV files concatenated into a single DataFrame.\n",
            "Prediction of SSH-Bruteforce\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "        Benign       0.00      0.00      0.00         0\n",
            "DoS-HTTP-Flood       0.00      0.00      0.00         0\n",
            "      PortScan       0.00      0.00      0.00         0\n",
            "SSH-Bruteforce       1.00      0.42      0.60      7225\n",
            "\n",
            "      accuracy                           0.42      7225\n",
            "     macro avg       0.25      0.11      0.15      7225\n",
            "  weighted avg       1.00      0.42      0.60      7225\n",
            "\n",
            "\n",
            "Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Benign  DoS-HTTP-Flood  DoS-Slow-Rate  FTP-Bruteforce  \\\n",
              "Benign               0               0              0               0   \n",
              "DoS-HTTP-Flood       0               0              0               0   \n",
              "DoS-Slow-Rate        0               0              0               0   \n",
              "FTP-Bruteforce       0               0              0               0   \n",
              "PortScan             0               0              0               0   \n",
              "SSH-Bruteforce    4137               2              0               0   \n",
              "\n",
              "                PortScan  SSH-Bruteforce  \n",
              "Benign                 0               0  \n",
              "DoS-HTTP-Flood         0               0  \n",
              "DoS-Slow-Rate          0               0  \n",
              "FTP-Bruteforce         0               0  \n",
              "PortScan               0               0  \n",
              "SSH-Bruteforce        16            3070  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c713a576-ecd5-4df7-82a9-a47207731607\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Benign</th>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <th>PortScan</th>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-HTTP-Flood</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slow-Rate</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP-Bruteforce</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PortScan</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "      <td>4137</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>3070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c713a576-ecd5-4df7-82a9-a47207731607')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c713a576-ecd5-4df7-82a9-a47207731607 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c713a576-ecd5-4df7-82a9-a47207731607');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8803066b-7dcf-4326-a3e5-d20c5dcde6e2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8803066b-7dcf-4326-a3e5-d20c5dcde6e2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8803066b-7dcf-4326-a3e5-d20c5dcde6e2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  make_prediction(model, df)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Benign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1688,\n        \"min\": 0,\n        \"max\": 4137,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4137,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-HTTP-Flood\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoS-Slow-Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FTP-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PortScan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 16,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SSH-Bruteforce\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1253,\n        \"min\": 0,\n        \"max\": 3070,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3070\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}